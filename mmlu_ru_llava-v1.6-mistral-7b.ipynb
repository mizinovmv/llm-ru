{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a5146af-3d1a-4922-8906-cda830e5894e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78723c7d-adeb-4f2c-be0a-915b0c702667",
   "metadata": {},
   "outputs": [],
   "source": [
    "subcategories = {\n",
    "    \"abstract_algebra\": [\"math\"],\n",
    "    \"anatomy\": [\"health\"],\n",
    "    \"astronomy\": [\"physics\"],\n",
    "    \"business_ethics\": [\"business\"],\n",
    "    \"clinical_knowledge\": [\"health\"],\n",
    "    \"college_biology\": [\"biology\"],\n",
    "    \"college_chemistry\": [\"chemistry\"],\n",
    "    \"college_computer_science\": [\"computer science\"],\n",
    "    \"college_mathematics\": [\"math\"],\n",
    "    \"college_medicine\": [\"health\"],\n",
    "    \"college_physics\": [\"physics\"],\n",
    "    \"computer_security\": [\"computer science\"],\n",
    "    \"conceptual_physics\": [\"physics\"],\n",
    "    \"econometrics\": [\"economics\"],\n",
    "    \"electrical_engineering\": [\"engineering\"],\n",
    "    \"elementary_mathematics\": [\"math\"],\n",
    "    \"formal_logic\": [\"philosophy\"],\n",
    "    \"global_facts\": [\"other\"],\n",
    "    \"high_school_biology\": [\"biology\"],\n",
    "    \"high_school_chemistry\": [\"chemistry\"],\n",
    "    \"high_school_computer_science\": [\"computer science\"],\n",
    "    \"high_school_european_history\": [\"history\"],\n",
    "    \"high_school_geography\": [\"geography\"],\n",
    "    \"high_school_government_and_politics\": [\"politics\"],\n",
    "    \"high_school_macroeconomics\": [\"economics\"],\n",
    "    \"high_school_mathematics\": [\"math\"],\n",
    "    \"high_school_microeconomics\": [\"economics\"],\n",
    "    \"high_school_physics\": [\"physics\"],\n",
    "    \"high_school_psychology\": [\"psychology\"],\n",
    "    \"high_school_statistics\": [\"math\"],\n",
    "    \"high_school_us_history\": [\"history\"],\n",
    "    \"high_school_world_history\": [\"history\"],\n",
    "    \"human_aging\": [\"health\"],\n",
    "    \"human_sexuality\": [\"culture\"],\n",
    "    \"international_law\": [\"law\"],\n",
    "    \"jurisprudence\": [\"law\"],\n",
    "    \"logical_fallacies\": [\"philosophy\"],\n",
    "    \"machine_learning\": [\"computer science\"],\n",
    "    \"management\": [\"business\"],\n",
    "    \"marketing\": [\"business\"],\n",
    "    \"medical_genetics\": [\"health\"],\n",
    "    \"miscellaneous\": [\"other\"],\n",
    "    \"moral_disputes\": [\"philosophy\"],\n",
    "    \"moral_scenarios\": [\"philosophy\"],\n",
    "    \"nutrition\": [\"health\"],\n",
    "    \"philosophy\": [\"philosophy\"],\n",
    "    \"prehistory\": [\"history\"],\n",
    "    \"professional_accounting\": [\"other\"],\n",
    "    \"professional_law\": [\"law\"],\n",
    "    \"professional_medicine\": [\"health\"],\n",
    "    \"professional_psychology\": [\"psychology\"],\n",
    "    \"public_relations\": [\"politics\"],\n",
    "    \"security_studies\": [\"politics\"],\n",
    "    \"sociology\": [\"culture\"],\n",
    "    \"us_foreign_policy\": [\"politics\"],\n",
    "    \"virology\": [\"health\"],\n",
    "    \"world_religions\": [\"philosophy\"],\n",
    "}\n",
    "\n",
    "categories = {\n",
    "    \"STEM\": [\"physics\", \"chemistry\", \"biology\", \"computer science\", \"math\", \"engineering\"],\n",
    "    \"humanities\": [\"history\", \"philosophy\", \"law\"],\n",
    "    \"social sciences\": [\"politics\", \"culture\", \"economics\", \"geography\", \"psychology\"],\n",
    "    \"other (business, health, misc.)\": [\"other\", \"business\", \"health\"],\n",
    "}\n",
    "\n",
    "# in the form to fit the prompt headline\n",
    "subcategories_en2ru = {\n",
    "    \"abstract_algebra\": \"абстрактной_алгебре\",\n",
    "    \"anatomy\": \"анатомии\",\n",
    "    \"astronomy\": \"астрономии\",\n",
    "    \"business_ethics\": \"деловой_этике\",\n",
    "    \"clinical_knowledge\": \"медицинским_знаниям\",\n",
    "    \"college_biology\": \"биологии_в_вузе\",\n",
    "    \"college_chemistry\": \"химии_в_вузе\",\n",
    "    \"college_computer_science\": \"компьютерным_наукам_в_вузе\",\n",
    "    \"college_mathematics\": \"математике_в_вузе\",\n",
    "    \"college_medicine\": \"медицине_в_вузе\",\n",
    "    \"college_physics\": \"физике_в_вузе\",\n",
    "    \"computer_security\": \"компьютерной_безопасности\",\n",
    "    \"conceptual_physics\": \"теоретической_физике\",\n",
    "    \"econometrics\": \"эконометрике\",\n",
    "    \"electrical_engineering\": \"электротехнике\",\n",
    "    \"elementary_mathematics\": \"элементарной_математике\",\n",
    "    \"formal_logic\": \"формальной_логике\",\n",
    "    \"global_facts\": \"фактам_о_мире\",\n",
    "    \"high_school_biology\": \"биологии_в_старшей_школе\",\n",
    "    \"high_school_chemistry\": \"химии_в_старшей_школе\",\n",
    "    \"high_school_computer_science\": \"информатике_в_старшей_школе\",\n",
    "    \"high_school_european_history\": \"истории_Европы_в_старшей_школе\",\n",
    "    \"high_school_geography\": \"географии_в_старшей_школе\",\n",
    "    \"high_school_government_and_politics\": \"государству_и_политике_в_старшей_школе\",\n",
    "    \"high_school_macroeconomics\": \"макроэкономике_в_старшей_школе\",\n",
    "    \"high_school_mathematics\": \"математике_в_старшей_школе\",\n",
    "    \"high_school_microeconomics\": \"микроэкономике_в_старшей_школе\",\n",
    "    \"high_school_physics\": \"физике_в_старшей_школе\",\n",
    "    \"high_school_psychology\": \"психологии_в_старшей_школе\",\n",
    "    \"high_school_statistics\": \"статистике_в_старшей_школе\",\n",
    "    \"high_school_us_history\": \"истории_США_в_старшей_школе\",\n",
    "    \"high_school_world_history\": \"всемирной_истории_в_старшей_школе\",\n",
    "    \"human_aging\": \"старению_человека\",\n",
    "    \"human_sexuality\": \"человеческой_сексуальности\",\n",
    "    \"international_law\": \"международному_праву\",\n",
    "    \"jurisprudence\": \"юриспруденции\",\n",
    "    \"logical_fallacies\": \"логическим_ошибкам\",\n",
    "    \"machine_learning\": \"машинному_обучению\",\n",
    "    \"management\": \"менеджменту\",\n",
    "    \"marketing\": \"маркетингу\",\n",
    "    \"medical_genetics\": \"медицинской_генетике\",\n",
    "    \"miscellaneous\": \"разным_темам\",\n",
    "    \"moral_disputes\": \"нравственным_спорам\",\n",
    "    \"moral_scenarios\": \"нравственным_сценариям\",\n",
    "    \"nutrition\": \"правильному_питанию\",\n",
    "    \"philosophy\": \"философии\",\n",
    "    \"prehistory\": \"доисторической_эпохе\",\n",
    "    \"professional_accounting\": \"профессиональному_бухгалтерскому_учету\",\n",
    "    \"professional_law\": \"профессиональному_праву\",\n",
    "    \"professional_medicine\": \"профессиональной_медицине\",\n",
    "    \"professional_psychology\": \"профессиональной_психологии\",\n",
    "    \"public_relations\": \"связям_с_общественностью\",\n",
    "    \"security_studies\": \"исследованиям_в_области_безопасности\",\n",
    "    \"sociology\": \"социологии\",\n",
    "    \"us_foreign_policy\": \"внешней_политике_США\",\n",
    "    \"virology\": \"вирусологии\",\n",
    "    \"world_religions\": \"мировым_религиям\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a48491ed-f0c6-4250-a422-ebec70877624",
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc\n",
    "import typing as tp\n",
    "\n",
    "class Conversation(abc.ABC):\n",
    "    \"\"\"\n",
    "    Inspired by https://github.com/lm-sys/FastChat/blob/main/fastchat/conversation.py\n",
    "    \"\"\"\n",
    "    def __init__(self, system_prompt: str, roles: tp.Tuple[str, str]):\n",
    "        self.system_prompt = system_prompt\n",
    "        self.roles = roles\n",
    "        self.messages: tp.List[tp.List[str, str]] = []\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def get_prompt(self) -> str:\n",
    "        pass\n",
    "\n",
    "    def update_last_message(self, text: str) -> None:\n",
    "        self.messages[-1] = (self.messages[-1][0], text)\n",
    "\n",
    "    def append_message(self, role: str, text: str) -> None:\n",
    "        self.messages.append({\"role\":role, \"content\":text})\n",
    "\n",
    "class EmptyConversation(Conversation):\n",
    "\n",
    "    #\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n{instruction}\\n\\n### Response:\"\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            system_prompt=\"\",\n",
    "            roles=(\"user\", \"assistant\"),\n",
    "        )\n",
    "\n",
    "    def get_prompt(self) -> str:\n",
    "        prompt = self.system_prompt\n",
    "        for m in self.messages:\n",
    "            prompt += str(m)\n",
    "        return prompt\n",
    "\n",
    "conversation_classes = {\n",
    "    \"empy_prompt_conv\": EmptyConversation,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc89932c-5691-4a3c-b809-5ee3e5788d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import pathlib\n",
    "import typing as tp\n",
    "\n",
    "import pandas as pd\n",
    "import datasets\n",
    "import peft\n",
    "import transformers\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "LANGUAGE_CONFIG: tp.Dict[str, tp.Dict[str, str]] = {\n",
    "    \"en\": {\n",
    "        \"headline_prefix\": \"The following are multiple choice questions (with answers) about\",\n",
    "        \"answer_prefix\": \"Answer:\",\n",
    "    },\n",
    "    \"ru\": {\n",
    "        \"headline_prefix\": \"Ниже приведены вопросы с множественным выбором (с ответами) по\",\n",
    "        \"answer_prefix\": \"Ответ:\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf49c5db-1a0a-4972-969b-fdaace80bc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_in_hendrycks_format(subject: str, split: str, lang: str) -> pd.DataFrame:\n",
    "    dataset = datasets.load_dataset(\"NLPCoreTeam/mmlu_ru\", name=subject, split=split)\n",
    "    wanted_cols = {\n",
    "        \"en\": [\"question_en\", \"choices_en\", \"answer\"],\n",
    "        \"ru\": [\"question_ru\", \"choices_ru\", \"answer\"],\n",
    "    }[lang]\n",
    "    df = dataset.to_pandas()[wanted_cols]\n",
    "    int2str = dataset.features[\"answer\"].int2str\n",
    "    df[df.columns[2]] = df[df.columns[2]].apply(lambda x: int2str(x))\n",
    "    df = pd.concat([\n",
    "        df[[df.columns[0]]],\n",
    "        pd.DataFrame(df[df.columns[1]].tolist()),\n",
    "        df[[df.columns[2]]],\n",
    "    ], axis=1)\n",
    "    df.columns = range(len(df.columns))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f72bdba4-05e7-4fd4-90d0-038b7ce1a930",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"liuhaotian/llava-v1.6-mistral-7b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30c6642c-dc4a-4b71-af78-c553fff4c3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/haotian-liu/LLaVA.git --no-dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "259d895a-c5af-4031-994d-ceccafb10425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch 2.1.2+cu121\n",
      "transformers 4.37.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d07b1cab9c943f7b47f46810c0a5e95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "LlavaMistralForCausalLM(\n",
       "  (model): LlavaMistralModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x MistralDecoderLayer(\n",
       "        (self_attn): MistralFlashAttention2(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): MistralRMSNorm()\n",
       "    (vision_tower): CLIPVisionTower(\n",
       "      (vision_tower): CLIPVisionModel(\n",
       "        (vision_model): CLIPVisionTransformer(\n",
       "          (embeddings): CLIPVisionEmbeddings(\n",
       "            (patch_embedding): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14), bias=False)\n",
       "            (position_embedding): Embedding(577, 1024)\n",
       "          )\n",
       "          (pre_layrnorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder): CLIPEncoder(\n",
       "            (layers): ModuleList(\n",
       "              (0-23): 24 x CLIPEncoderLayer(\n",
       "                (self_attn): CLIPAttention(\n",
       "                  (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                )\n",
       "                (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): CLIPMLP(\n",
       "                  (activation_fn): QuickGELUActivation()\n",
       "                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                )\n",
       "                (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (post_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (mm_projector): Sequential(\n",
       "      (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "from llava.model.builder import load_pretrained_model\n",
    "from llava.mm_utils import get_model_name_from_path\n",
    "\n",
    "print(\"torch\", torch.__version__)\n",
    "print(\"transformers\", transformers.__version__)\n",
    "\n",
    "device_map = \"auto\"\n",
    "max_memory = None\n",
    "max_memory = {0:\"24GiB\"}\n",
    "\n",
    "tokenizer, model, image_processor, context_len = load_pretrained_model(\n",
    "    model_path=model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    model_base=None,\n",
    "    model_name=get_model_name_from_path(model_id),\n",
    "    use_flash_attn=True,\n",
    "    device_map=device_map,\n",
    "    max_memory=max_memory,\n",
    ")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1673878a-3eb4-4421-a7f5-f21787faed8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaTokenizerFast(name_or_path='liuhaotian/llava-v1.6-mistral-7b', vocab_size=32000, model_max_length=4096, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<unk>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from transformers import AutoTokenizer\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=False)\n",
    "# tokenizer.add_special_tokens({\n",
    "#     \"eos_token\": tokenizer.convert_ids_to_tokens(model.config.eos_token_id),\n",
    "#     \"bos_token\": tokenizer.convert_ids_to_tokens(model.config.bos_token_id),\n",
    "#     \"cls_token\": tokenizer.convert_ids_to_tokens(model.config.eos_token_id),\n",
    "#     \"sep_token\": tokenizer.convert_ids_to_tokens(model.config.eos_token_id),\n",
    "#     \"mask_token\": tokenizer.convert_ids_to_tokens(model.config.eos_token_id),\n",
    "#     \"pad_token\": tokenizer.convert_ids_to_tokens(model.config.eos_token_id),\n",
    "# })\n",
    "# tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81eff76c-d0ac-4f92-81e6-1ebce44e822e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_subject(subject: str) -> str:\n",
    "    l = subject.split(\"_\")\n",
    "    s = \"\"\n",
    "    for entry in l:\n",
    "        s += \" \" + entry\n",
    "    return s.strip()\n",
    "\n",
    "def get_pretty_subject(subject: str, lang: str) -> str:\n",
    "    return format_subject({\n",
    "        \"en\": subject,\n",
    "        \"ru\": subcategories_en2ru[subject],  # predefined map\n",
    "    }[lang])\n",
    "\n",
    "def get_prompt_from_dataframes(dev_df: pd.DataFrame, test_df: pd.DataFrame,\n",
    "                               k: int, test_iloc_idx: int, lang: str, subject: str, conversation_type: str):\n",
    "    assert 0 <= k <= 5\n",
    "    headline_prefix = LANGUAGE_CONFIG[lang][\"headline_prefix\"]\n",
    "    headline_postfix = get_pretty_subject(subject=subject, lang=lang)\n",
    "    headline = f\"{headline_prefix} {headline_postfix}.\\n\\n\"\n",
    "\n",
    "    answer_prefix = LANGUAGE_CONFIG[lang][\"answer_prefix\"]\n",
    "\n",
    "    conv = conversation_classes[conversation_type]()\n",
    "\n",
    "    is_already_taken_headline = False\n",
    "    for row_idx, row in dev_df.head(k).iterrows():\n",
    "        q = row[0]\n",
    "        options = row[1:5].tolist()\n",
    "        lettered_options = [f\"{x}. {y}\" for x, y in zip([\"A\", \"B\", \"C\", \"D\"], options)]\n",
    "        q_with_lettered_options = \"\\n\".join([q, \"\\n\".join(lettered_options)])\n",
    "        if row_idx == 0:\n",
    "            q_with_lettered_options = headline + q_with_lettered_options\n",
    "            is_already_taken_headline = True\n",
    "        conv.append_message(conv.roles[0], q_with_lettered_options)\n",
    "        a = row[5]\n",
    "        \n",
    "        # if is not instruct, needed to be manually separated for mmlu examples\n",
    "        conv.append_message(conv.roles[1], f\"{answer_prefix}{a}\")\n",
    "\n",
    "    row = test_df.iloc[test_iloc_idx]\n",
    "    q = row[0]\n",
    "    options = row[1:5].tolist()\n",
    "    lettered_options = [f\"{x}. {y}\" for x, y in zip([\"A\", \"B\", \"C\", \"D\"], options)]\n",
    "    q_with_lettered_options = \"\\n\".join([q, \"\\n\".join(lettered_options)])\n",
    "    if not is_already_taken_headline:\n",
    "        q_with_lettered_options = headline + q_with_lettered_options\n",
    "        is_already_taken_headline = True\n",
    "    conv.append_message(conv.roles[0], q_with_lettered_options)\n",
    "    a = row[5]\n",
    "    conv.append_message(conv.roles[1], answer_prefix)\n",
    "    # prompt = f\"{conv.get_prompt()}{answer_prefix}\"\n",
    "    return conv.messages\n",
    "\n",
    "def calculate_token_interest_probs(\n",
    "    input_ids,\n",
    "    tokenizer: transformers.PreTrainedTokenizerBase,\n",
    "    model: tp.Union[transformers.PreTrainedModel, peft.peft_model.PeftModelForCausalLM],\n",
    ") -> tp.Dict[str, float]:    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids)\n",
    "    logits = outputs.logits  # shape (batch_size, sequence_length, vocab_size)\n",
    "    next_token_logits = logits[:, -1, :]  # shape (batch_size, vocab_size)\n",
    "\n",
    "    next_token_logits = next_token_logits.flatten()\n",
    "    assert next_token_logits.shape == torch.Size((model.config.vocab_size, ))\n",
    "\n",
    "    next_token_probs = torch.nn.functional.softmax(next_token_logits, dim=-1).cpu()  # all probs over vocab\n",
    "    # assert torch.isclose(next_token_probs.sum(), torch.tensor(1.0).to(next_token_probs.dtype), atol=1e-03)  # dtype for half/nothalf, -03 for float16\n",
    "    \n",
    "    tokens_of_interest = [\n",
    "        tokenizer(\"A\", add_special_tokens=False).input_ids[-1],\n",
    "        tokenizer(\"B\", add_special_tokens=False).input_ids[-1],\n",
    "        tokenizer(\"C\", add_special_tokens=False).input_ids[-1],\n",
    "        tokenizer(\"D\", add_special_tokens=False).input_ids[-1],\n",
    "    ]\n",
    "\n",
    "    probs = next_token_probs[tokens_of_interest].tolist()\n",
    "    res = dict(zip([\"A\", \"B\", \"C\", \"D\"], probs))\n",
    "    return res\n",
    "\n",
    "def append_to_jsonl(data: list, filename: str) -> None:\n",
    "    with open(filename, \"a\") as f:\n",
    "        f.write(json.dumps(data) + \"\\n\")\n",
    "\n",
    "def evaluate_subject(\n",
    "    subject: str,\n",
    "    lang: str,\n",
    "    k_shot: int,\n",
    "    jsonl_filepath: str,\n",
    "    maxlen: int,\n",
    "    convtype: str,\n",
    "    tokenizer: transformers.PreTrainedTokenizerBase,\n",
    "    model: tp.Union[transformers.PreTrainedModel, peft.peft_model.PeftModelForCausalLM],\n",
    ") -> None:\n",
    "\n",
    "    dev_df = get_df_in_hendrycks_format(subject=subject, split=\"dev\", lang=lang)\n",
    "    test_df = get_df_in_hendrycks_format(subject=subject, split=\"test\", lang=lang)\n",
    "\n",
    "    for idx, row in tqdm(test_df.iterrows(), total=len(test_df), desc=subject):\n",
    "\n",
    "        current_k_shot = k_shot\n",
    "        skip_too_lengthy = False\n",
    "        while True:\n",
    "            if current_k_shot < 0:\n",
    "                logger.info(\"Skip too lengthy.\")\n",
    "                skip_too_lengthy = True\n",
    "                break\n",
    "            input_messages = get_prompt_from_dataframes(\n",
    "                dev_df=dev_df,\n",
    "                test_df=test_df,\n",
    "                k=current_k_shot,\n",
    "                test_iloc_idx=idx,\n",
    "                lang=lang,\n",
    "                subject=subject,\n",
    "                conversation_type=convtype,\n",
    "            )\n",
    "            input_prompt = tokenizer.apply_chat_template(input_messages, tokenize=False, add_special_tokens=False)[:-len(tokenizer.eos_token)]\n",
    "            input_ids = tokenizer.encode(input_prompt, return_tensors=\"pt\", add_special_tokens=False).to(model.device)\n",
    "\n",
    "            if input_ids.shape[-1] > maxlen and current_k_shot >= 0:\n",
    "                logger.info(\"Takes smaller current_k_shot since maxlen.\")\n",
    "                current_k_shot -= 1\n",
    "            elif current_k_shot < 0:\n",
    "                logger.info(\"Skip too lengthy.\")\n",
    "                skip_too_lengthy = True\n",
    "            else:\n",
    "                break\n",
    "        if skip_too_lengthy:\n",
    "            continue\n",
    "\n",
    "        label = row[5]\n",
    "\n",
    "        preds = calculate_token_interest_probs(\n",
    "            input_ids=input_ids,\n",
    "            tokenizer=tokenizer,\n",
    "            model=model,\n",
    "        )\n",
    "\n",
    "        append_to_jsonl(data=[input_prompt, label, preds], filename=jsonl_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3935963-d5d7-4b60-b69c-08436870a4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] Ниже приведены вопросы с множественным выбором (с ответами) по абстрактной алгебре.\n",
      "\n",
      "Найдите все c в Z_3 таким образом, чтобы Z_3[x]/(x ^ 2 + c) было полем.\n",
      "A. 0\n",
      "B. 1\n",
      "C. 2\n",
      "D. 3 [/INST]Ответ:B</s>[INST] Утверждение 1 | Если aH является элементом факторной группы, то |aH| делит |a|. Утверждение 2 | Если H и K являются подгруппами G, то HK является подгруппой G.\n",
      "A. Верно, верно\n",
      "B. Ложь, ложь\n",
      "C. Правда, ложь\n",
      "D. Ложь, истина [/INST]Ответ:B</s>[INST] Утверждение 1 | Каждый элемент группы порождает циклическую подгруппу группы. Утверждение 2 | Симметричная группа S_10 состоит из 10 элементов.\n",
      "A. Верно, верно\n",
      "B. Ложь, ложь\n",
      "C. Правда, ложь\n",
      "D. Ложь, истина [/INST]Ответ:C</s>[INST] Утверждение 1| Каждая функция из конечного множества на саму себя должна быть один к одному. Утверждение 2 | Каждая подгруппа абелевой группы является абелевой.\n",
      "A. Верно, верно\n",
      "B. Ложь, ложь\n",
      "C. Правда, ложь\n",
      "D. Ложь, истина [/INST]Ответ:A</s>[INST] Найдите характеристику кольца 2Z.\n",
      "A. 0\n",
      "B. 3\n",
      "C. 12\n",
      "D. 30 [/INST]Ответ:A</s>[INST] Найдите степень для данного расширения поля Q(sqrt(2), sqrt(3), sqrt(18)) над Q.\n",
      "A. 0\n",
      "B. 4\n",
      "C. 2\n",
      "D. 6 [/INST]Ответ:\n",
      "CPU times: user 1.03 s, sys: 35 ms, total: 1.07 s\n",
      "Wall time: 3.99 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<s>D </s>'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "lang = \"ru\"\n",
    "subject = \"abstract_algebra\"\n",
    "convtype = \"empy_prompt_conv\"\n",
    "current_k_shot = 5\n",
    "idx = 0\n",
    "dev_df = get_df_in_hendrycks_format(subject=subject, split=\"dev\", lang=lang)\n",
    "test_df = get_df_in_hendrycks_format(subject=subject, split=\"test\", lang=lang)\n",
    "\n",
    "input_messages = get_prompt_from_dataframes(\n",
    "    dev_df=dev_df,\n",
    "    test_df=test_df,\n",
    "    k=current_k_shot,\n",
    "    test_iloc_idx=idx,\n",
    "    lang=lang,\n",
    "    subject=subject,\n",
    "    conversation_type=convtype,\n",
    ")\n",
    "input_prompt = tokenizer.apply_chat_template(input_messages, tokenize=False, add_special_tokens=False)[:-len(tokenizer.eos_token)]\n",
    "print(input_prompt)\n",
    "input_ids = tokenizer.encode(input_prompt, return_tensors=\"pt\", add_special_tokens=False).to(model.device)\n",
    "output_ids = model.generate(input_ids, pad_token_id=tokenizer.eos_token_id, max_new_tokens=10)\n",
    "ouput_str = tokenizer.decode(output_ids[0])\n",
    "ouput_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8e07f7-1edf-4ecf-a86c-ecee3959fe01",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"mmlu_ru_llava-v1.6-mistral-7b\"\n",
    "lang = \"ru\"\n",
    "k_shot = 5\n",
    "maxlen = 8192\n",
    "model.config.sliding_window = maxlen\n",
    "convtype = \"empy_prompt_conv\"\n",
    "\n",
    "subjects = list(subcategories.keys())\n",
    "for each_subject in subjects:\n",
    "    jsonl_filepath = str(pathlib.Path(output_dir) / f\"{each_subject}.jsonl\")\n",
    "    pathlib.Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "    logger.info(f\"Filepath JSONL: {jsonl_filepath}\")\n",
    "    if pathlib.Path(jsonl_filepath).exists():\n",
    "        logger.info(f\"File already exists! Please manually verify that it wasn't partially interrupted.\")\n",
    "        continue\n",
    "    evaluate_subject(\n",
    "            subject=each_subject,\n",
    "            lang=lang,\n",
    "            k_shot=k_shot,\n",
    "            jsonl_filepath=jsonl_filepath,\n",
    "            maxlen=maxlen, convtype=convtype,\n",
    "            tokenizer=tokenizer,\n",
    "            model=model,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cafd3203-0f79-434e-8466-7e67c9c4b475",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"mmlu_ru_llava-v1.6-mistral-7b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc0ae2ce-8cce-4b80-a940-70caa34f3d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mmlu_ru_llava-v1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46.78635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mmlu_ru_llava-v1\n",
       "0          46.78635"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "category_to_main_category = {value: key for key, sublist in categories.items() for value in sublist}\n",
    "subcategories2categories = {key: category_to_main_category[value[0]] for key, value in subcategories.items()}\n",
    "\n",
    "def calculate_accuracy_from_directory(dirpath: str) -> tp.Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    assert pathlib.Path(dirpath).exists()\n",
    "    filepaths = [str(x) for x in pathlib.Path(dirpath).glob('*.jsonl')]\n",
    "    # assert len(filepaths) == 57\n",
    "    res = {}\n",
    "    for each_filepath in filepaths:\n",
    "        df = pd.read_json(each_filepath, lines=True)\n",
    "        df.columns = ['prompt', 'label', 'preds']\n",
    "        cors = []\n",
    "        for idx, row in df.iterrows():\n",
    "            preds = row['preds']\n",
    "            best_idx = np.argmax(list(preds.values()))\n",
    "            y_pred = list(preds.keys())[best_idx]\n",
    "            y_true = row['label']\n",
    "            y_pred = y_pred.strip()\n",
    "            y_true = y_true.strip()\n",
    "            cors.append(y_true == y_pred)\n",
    "        acc = np.mean(cors)\n",
    "        res[pathlib.Path(each_filepath).stem] = acc * 100\n",
    "    \n",
    "    df = pd.DataFrame({pathlib.Path(dirpath).stem: res}).reset_index()\n",
    "    df = df.rename(columns={'index': 'subcategory'})\n",
    "    subcategories_df = df.copy()\n",
    "    \n",
    "    df = subcategories_df.copy()\n",
    "    df['subcategory'] = df['subcategory'].map(subcategories2categories)\n",
    "    df = df.rename(columns={'subcategory': 'category'})\n",
    "    df = df.groupby('category').mean().reset_index()\n",
    "    categories_df = df.copy()\n",
    "    \n",
    "    total_df = pd.DataFrame({pathlib.Path(dirpath).stem: [categories_df[pathlib.Path(dirpath).stem].mean()]})\n",
    "    \n",
    "    # assert subcategories_df.shape == (57, 2)\n",
    "    # assert categories_df.shape == (4, 2)\n",
    "    # assert total_df.shape == (1, 1)\n",
    "    return (subcategories_df, categories_df, total_df)\n",
    "\n",
    "subcategories_df, categories_df, total_df = calculate_accuracy_from_directory(dirpath=output_dir)\n",
    "print(total_df.shape)\n",
    "total_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ea70f8f-336c-4b32-98c0-5c0b81210a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>mmlu_ru_llava-v1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>STEM</td>\n",
       "      <td>38.429018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>humanities</td>\n",
       "      <td>50.926774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>other (business, health, misc.)</td>\n",
       "      <td>45.215376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>social sciences</td>\n",
       "      <td>52.574234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          category  mmlu_ru_llava-v1\n",
       "0                             STEM         38.429018\n",
       "1                       humanities         50.926774\n",
       "2  other (business, health, misc.)         45.215376\n",
       "3                  social sciences         52.574234"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c61a104-ac1e-4925-ab32-6221d3124e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subcategory</th>\n",
       "      <th>mmlu_ru_llava-v1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abstract_algebra</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anatomy</td>\n",
       "      <td>37.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>astronomy</td>\n",
       "      <td>44.078947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business_ethics</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>clinical_knowledge</td>\n",
       "      <td>43.018868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>college_biology</td>\n",
       "      <td>40.277778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>college_chemistry</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>college_computer_science</td>\n",
       "      <td>38.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>college_mathematics</td>\n",
       "      <td>32.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>college_medicine</td>\n",
       "      <td>40.462428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>college_physics</td>\n",
       "      <td>23.529412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>computer_security</td>\n",
       "      <td>64.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>conceptual_physics</td>\n",
       "      <td>39.148936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>econometrics</td>\n",
       "      <td>33.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>electrical_engineering</td>\n",
       "      <td>46.896552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>elementary_mathematics</td>\n",
       "      <td>35.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>formal_logic</td>\n",
       "      <td>34.920635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>global_facts</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>high_school_biology</td>\n",
       "      <td>50.645161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>high_school_chemistry</td>\n",
       "      <td>35.960591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>high_school_computer_science</td>\n",
       "      <td>56.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>high_school_european_history</td>\n",
       "      <td>60.606061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>high_school_geography</td>\n",
       "      <td>55.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>high_school_government_and_politics</td>\n",
       "      <td>55.440415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>high_school_macroeconomics</td>\n",
       "      <td>45.128205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>high_school_mathematics</td>\n",
       "      <td>28.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>high_school_microeconomics</td>\n",
       "      <td>44.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>high_school_physics</td>\n",
       "      <td>27.814570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>high_school_psychology</td>\n",
       "      <td>57.064220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>high_school_statistics</td>\n",
       "      <td>31.481481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>high_school_us_history</td>\n",
       "      <td>62.745098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>high_school_world_history</td>\n",
       "      <td>62.447257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>human_aging</td>\n",
       "      <td>47.085202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>human_sexuality</td>\n",
       "      <td>51.145038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>international_law</td>\n",
       "      <td>66.115702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>jurisprudence</td>\n",
       "      <td>53.703704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>logical_fallacies</td>\n",
       "      <td>47.852761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>machine_learning</td>\n",
       "      <td>39.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>management</td>\n",
       "      <td>57.281553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>marketing</td>\n",
       "      <td>73.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>medical_genetics</td>\n",
       "      <td>46.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>miscellaneous</td>\n",
       "      <td>53.512133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>moral_disputes</td>\n",
       "      <td>48.554913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>moral_scenarios</td>\n",
       "      <td>25.921788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>nutrition</td>\n",
       "      <td>53.267974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>philosophy</td>\n",
       "      <td>57.877814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>prehistory</td>\n",
       "      <td>49.382716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>professional_accounting</td>\n",
       "      <td>32.978723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>professional_law</td>\n",
       "      <td>32.855280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>professional_medicine</td>\n",
       "      <td>36.397059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>professional_psychology</td>\n",
       "      <td>41.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>public_relations</td>\n",
       "      <td>52.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>security_studies</td>\n",
       "      <td>62.040816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>sociology</td>\n",
       "      <td>65.671642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>us_foreign_policy</td>\n",
       "      <td>67.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>virology</td>\n",
       "      <td>39.156627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>world_religions</td>\n",
       "      <td>59.064327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            subcategory  mmlu_ru_llava-v1\n",
       "0                      abstract_algebra         28.000000\n",
       "1                               anatomy         37.777778\n",
       "2                             astronomy         44.078947\n",
       "3                       business_ethics         45.000000\n",
       "4                    clinical_knowledge         43.018868\n",
       "5                       college_biology         40.277778\n",
       "6                     college_chemistry         30.000000\n",
       "7              college_computer_science         38.000000\n",
       "8                   college_mathematics         32.000000\n",
       "9                      college_medicine         40.462428\n",
       "10                      college_physics         23.529412\n",
       "11                    computer_security         64.000000\n",
       "12                   conceptual_physics         39.148936\n",
       "13                         econometrics         33.333333\n",
       "14               electrical_engineering         46.896552\n",
       "15               elementary_mathematics         35.714286\n",
       "16                         formal_logic         34.920635\n",
       "17                         global_facts         28.000000\n",
       "18                  high_school_biology         50.645161\n",
       "19                high_school_chemistry         35.960591\n",
       "20         high_school_computer_science         56.000000\n",
       "21         high_school_european_history         60.606061\n",
       "22                high_school_geography         55.555556\n",
       "23  high_school_government_and_politics         55.440415\n",
       "24           high_school_macroeconomics         45.128205\n",
       "25              high_school_mathematics         28.888889\n",
       "26           high_school_microeconomics         44.117647\n",
       "27                  high_school_physics         27.814570\n",
       "28               high_school_psychology         57.064220\n",
       "29               high_school_statistics         31.481481\n",
       "30               high_school_us_history         62.745098\n",
       "31            high_school_world_history         62.447257\n",
       "32                          human_aging         47.085202\n",
       "33                      human_sexuality         51.145038\n",
       "34                    international_law         66.115702\n",
       "35                        jurisprudence         53.703704\n",
       "36                    logical_fallacies         47.852761\n",
       "37                     machine_learning         39.285714\n",
       "38                           management         57.281553\n",
       "39                            marketing         73.076923\n",
       "40                     medical_genetics         46.000000\n",
       "41                        miscellaneous         53.512133\n",
       "42                       moral_disputes         48.554913\n",
       "43                      moral_scenarios         25.921788\n",
       "44                            nutrition         53.267974\n",
       "45                           philosophy         57.877814\n",
       "46                           prehistory         49.382716\n",
       "47              professional_accounting         32.978723\n",
       "48                     professional_law         32.855280\n",
       "49                professional_medicine         36.397059\n",
       "50              professional_psychology         41.666667\n",
       "51                     public_relations         52.727273\n",
       "52                     security_studies         62.040816\n",
       "53                            sociology         65.671642\n",
       "54                    us_foreign_policy         67.000000\n",
       "55                             virology         39.156627\n",
       "56                      world_religions         59.064327"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subcategories_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1092d7-ba00-4591-adcc-22ba7fbf3c47",
   "metadata": {},
   "source": [
    "### MMMU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01dc37f2-312a-44c6-bdab-41cf2573f7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import pathlib\n",
    "import typing as tp\n",
    "\n",
    "import pandas as pd\n",
    "import datasets\n",
    "import re\n",
    "import peft\n",
    "import transformers\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "LANGUAGE_CONFIG: tp.Dict[str, tp.Dict[str, str]] = {\n",
    "    \"en\": {\n",
    "        \"headline_prefix\": \"The following are multiple choice questions (with answers) about\",\n",
    "        \"answer_prefix\": \"Answer:\",\n",
    "    },\n",
    "    \"ru\": {\n",
    "        \"headline_prefix\": \"Ниже приведены вопросы с множественным выбором (с ответами) по\",\n",
    "        \"answer_prefix\": \"Ответ:\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d9d04b6-1eac-42d2-84ea-e0067c38e2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/MMMU-Benchmark/MMMU.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2a44b83-3ba8-4c64-bb89-447e49335060",
   "metadata": {},
   "outputs": [],
   "source": [
    "MMMU_DOMAIN_CAT2SUB_CAT = {\n",
    "  'Art and Design': ['Art', 'Art_Theory', 'Design', 'Music'],\n",
    "  'Business': ['Accounting', 'Economics', 'Finance', 'Manage','Marketing'],\n",
    "  'Science': ['Biology', 'Chemistry', 'Geography', 'Math', 'Physics',],\n",
    "  'Health and Medicine': ['Basic_Medical_Science', 'Clinical_Medicine', 'Diagnostics_and_Laboratory_Medicine', 'Pharmacy', 'Public_Health'],\n",
    "  'Humanities and Social Science': ['History', 'Literature', 'Sociology', 'Psychology'],\n",
    "  'Tech and Engineering': ['Agriculture', 'Architecture_and_Engineering', 'Computer_Science', 'Electronics', 'Energy_and_Power', 'Materials', 'Mechanical_Engineering'],\n",
    "}\n",
    "\n",
    "MMMU_SUBJECTS_EN2RU = {\n",
    "    'Accounting': \"Бухгалтерский учет\",\n",
    "    'Agriculture': \"Cельское хозяйство\",\n",
    "    'Architecture_and_Engineering': \"Архитектура_и_Инжиниринг\",\n",
    "    'Art': \"Искусство\",\n",
    "    'Art_Theory': \"Арт_Теория\",\n",
    "    'Basic_Medical_Science': \"Базовая_медицинская_наука\",\n",
    "    'Biology': \"Биология\",\n",
    "    'Chemistry': \"Химия\",\n",
    "    'Clinical_Medicine': \"Клиническая медицина\",\n",
    "    'Computer_Science': \"Информатика\",\n",
    "    'Design': \"Дизайн\",\n",
    "    'Diagnostics_and_Laboratory_Medicine': \"Диагностика_и_Лаборатория_Медицина\",\n",
    "    'Economics': \"Экономика\",\n",
    "    'Electronics': \"Электроника\",\n",
    "    'Energy_and_Power': \"Энергия_и_Мощность\",\n",
    "    'Finance': \"Финансы\",\n",
    "    'Geography': \"География\",\n",
    "    'History': \"История\",\n",
    "    'Literature': \"Литература\",\n",
    "    'Manage': \"Управление\",\n",
    "    'Marketing': \"Маркетинг\",\n",
    "    'Materials': \"Материалы\",\n",
    "    'Math': \"Математика\",\n",
    "    'Mechanical_Engineering': \"Машиностроение\",\n",
    "    'Music': \"Музыка\",\n",
    "    'Pharmacy': \"Аптека\",\n",
    "    'Physics': \"Физика\",\n",
    "    'Psychology': \"Психология\",\n",
    "    'Public_Health': \"Здравоохранение\",\n",
    "    'Sociology': \"Социология\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f819248-fbf7-403f-b0e1-833b53939f77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'question', 'options', 'explanation', 'image_1', 'image_2', 'image_3', 'image_4', 'image_5', 'image_6', 'image_7', 'img_type', 'answer', 'topic_difficulty', 'question_type', 'subfield'],\n",
       "    num_rows: 30\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject = \"Energy_and_Power\"\n",
    "split = \"validation\"\n",
    "dataset = datasets.load_dataset(\"MMMU/MMMU\", name=subject, split=split)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e296eff-710e-4ba8-a024-756c60da4730",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_img_path(text):\n",
    "    matches = re.findall(\"<img='(.*?)'>\", text)\n",
    "    return matches\n",
    "\n",
    "def process_single_sample(data):\n",
    "    question = data['question']\n",
    "    o_imgs_paths = []\n",
    "    for option in data['options']:\n",
    "        current_o_imgs_paths = parse_img_path(option)\n",
    "        for img_path in current_o_imgs_paths:\n",
    "            o_imgs_paths.append(img_path)\n",
    "\n",
    "    if len(o_imgs_paths) > 1:  # multiple images in options, used for random selection\n",
    "        return {'id': data['id'], 'question': question, 'options': data['options'], 'answer': data['answer'],\n",
    "             'image': None, 'question_type': data['question_type']}\n",
    "    else:\n",
    "        return {'id': data['id'], 'question': question, 'options': data['options'], 'answer': data['answer'],\n",
    "             'image': data['image_1'], 'question_type': data['question_type']}\n",
    "\n",
    "def construct_prompt(sample, config):\n",
    "    question = sample['question']\n",
    "    options = eval(sample['options'])\n",
    "    example = \"\"\n",
    "    if sample['question_type'] == 'multiple-choice':\n",
    "        start_chr = 'A'\n",
    "        prediction_range = []\n",
    "        index2ans = {}\n",
    "        for option in options:\n",
    "            prediction_range.append(start_chr)\n",
    "            example += f\"({start_chr}) {option}\\n\"\n",
    "            index2ans[start_chr] = option\n",
    "            start_chr = chr(ord(start_chr) + 1)\n",
    "        empty_prompt_sample_structure = config['multi_choice_example_format']\n",
    "        empty_prompt = empty_prompt_sample_structure.format(question, example)\n",
    "        res_dict = {}\n",
    "        res_dict['index2ans'] = index2ans\n",
    "        res_dict['correct_choice'] = sample['answer']\n",
    "        res_dict['all_choices'] = prediction_range\n",
    "        res_dict['empty_prompt'] = empty_prompt\n",
    "        if config['task_instructions']:\n",
    "            res_dict['final_input_prompt'] = config['task_instructions'].strip() + '\\n\\n' + empty_prompt\n",
    "        else:\n",
    "            res_dict['final_input_prompt'] = empty_prompt\n",
    "\n",
    "        res_dict['gt_content'] = options[ord(sample['answer'].upper()) - ord('A')]\n",
    "    else:\n",
    "        empty_prompt_sample_structure = config['short_ans_example_format']\n",
    "        empty_prompt = empty_prompt_sample_structure.format(question)\n",
    "        res_dict = {}\n",
    "        res_dict['empty_prompt'] = empty_prompt\n",
    "        if config['task_instructions']:\n",
    "            res_dict['final_input_prompt'] = config['task_instructions'].strip() + '\\n\\n' + empty_prompt\n",
    "        else:\n",
    "            res_dict['final_input_prompt'] = empty_prompt\n",
    "        res_dict['gt_content'] = sample['answer']\n",
    "\n",
    "    res_dict.update(sample)\n",
    "    return res_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98faca83-a99f-4565-a2cf-9ef5be2b2eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task_instructions': '',\n",
       " 'multi_choice_example_format': \"{}\\n{}\\nAnswer with the option's letter from the given choices directly.\",\n",
       " 'short_ans_example_format': '{}\\nAnswer the question using a single word or phrase.',\n",
       " 'temperature': '1e-6'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "mmmu_config =  {\n",
    "    \"llava_en\":\n",
    "\"\"\"\n",
    "task_instructions:\n",
    "- \"\"\n",
    "\n",
    "multi_choice_example_format:\n",
    "- \"{}\n",
    "\n",
    "{}\n",
    "\n",
    "Answer with the option's letter from the given choices directly.\"\n",
    "\n",
    "short_ans_example_format:\n",
    "- \"{}\n",
    "\n",
    "Answer the question using a single word or phrase.\"\n",
    "temperature:\n",
    "- 1e-6\n",
    "\"\"\",\n",
    "    \"llava_ru\":\n",
    "\"\"\"\n",
    "task_instructions:\n",
    "- \"\"\n",
    "multi_choice_example_format:\n",
    "- \"{}\n",
    "\n",
    "{}\n",
    "\n",
    "Ответь одной буквой только из приведенных вариантов.\"\n",
    "\n",
    "short_ans_example_format:\n",
    "- \"{}\n",
    "\n",
    "Ответьте на вопрос, используя одно слово или фразу.\"\n",
    "temperature:\n",
    "- 0\n",
    "\"\"\"\n",
    "}\n",
    "\n",
    "config = yaml.safe_load(mmmu_config[\"llava_en\"])\n",
    "for key, value in config.items():\n",
    "    if key != 'eval_params' and type(value) == list:\n",
    "        assert len(value) == 1, 'key {} has more than one value'.format(key)\n",
    "        config[key] = value[0]\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f83c646f-c79d-4868-a8a9-7df4830fee28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'index2ans': {'A': '0.04 kg/s', 'B': '4.19 kg/s', 'C': '5.25 kg/s'}, 'correct_choice': 'C', 'all_choices': ['A', 'B', 'C'], 'empty_prompt': \"An open water jet exits from a nozzle into sea-level air, as shown, and strikes a stagnation tube. If the centerline pressure at section (1) is 110 kPa and losses are neglected, estimate the mass flow in kg/s. <image 1>\\n(A) 0.04 kg/s\\n(B) 4.19 kg/s\\n(C) 5.25 kg/s\\n\\nAnswer with the option's letter from the given choices directly.\", 'final_input_prompt': \"An open water jet exits from a nozzle into sea-level air, as shown, and strikes a stagnation tube. If the centerline pressure at section (1) is 110 kPa and losses are neglected, estimate the mass flow in kg/s. <image 1>\\n(A) 0.04 kg/s\\n(B) 4.19 kg/s\\n(C) 5.25 kg/s\\n\\nAnswer with the option's letter from the given choices directly.\", 'gt_content': '5.25 kg/s', 'id': 'validation_Energy_and_Power_3', 'question': 'An open water jet exits from a nozzle into sea-level air, as shown, and strikes a stagnation tube. If the centerline pressure at section (1) is 110 kPa and losses are neglected, estimate the mass flow in kg/s. <image 1>', 'options': \"['0.04 kg/s', '4.19 kg/s', '5.25 kg/s']\", 'answer': 'C', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=414x210 at 0x7F5CFA33D0C0>, 'question_type': 'multiple-choice'}\n",
      "[INST] An open water jet exits from a nozzle into sea-level air, as shown, and strikes a stagnation tube. If the centerline pressure at section (1) is 110 kPa and losses are neglected, estimate the mass flow in kg/s. <image>\n",
      "(A) 0.04 kg/s\n",
      "(B) 4.19 kg/s\n",
      "(C) 5.25 kg/s\n",
      "\n",
      "Answer with the option's letter from the given choices directly. [/INST]\n",
      "{'pred_ans': 'A'}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=414x210 at 0x7F5CFA33D0C0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llava.constants import IMAGE_TOKEN_INDEX\n",
    "from llava.mm_utils import tokenizer_image_token, process_images, load_image_from_base64\n",
    "from llava.conversation import conv_templates\n",
    "\n",
    "LLMV_TEMPERATURE = 0.02\n",
    "LLMV_COV_MODEL = \"mistral_instruct\"\n",
    "\n",
    "def mmmu_eval(x, debug=False):\n",
    "    sample = process_single_sample(x)\n",
    "    sample = construct_prompt(sample, config = config)\n",
    "    if debug:\n",
    "        print(sample)\n",
    "    conv = conv_templates[LLMV_COV_MODEL].copy()\n",
    "    conv.system = \"\"\n",
    "    conv.append_message(conv.roles[0], sample[\"final_input_prompt\"].replace(\"<image 1>\", \"<image>\"))\n",
    "    conv.append_message(conv.roles[1], None)\n",
    "    prompt = conv.get_prompt()\n",
    "    if debug:\n",
    "        print(prompt)\n",
    "    input_ids = tokenizer_image_token(prompt, tokenizer, IMAGE_TOKEN_INDEX, return_tensors='pt').unsqueeze(0).to(\"cuda:0\")\n",
    "    \n",
    "    images = [sample[\"image\"]]\n",
    "    image_sizes = [x.size for x in images]\n",
    "    image_tensor = process_images(images, image_processor, model.config)[0]\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        output_ids = model.generate(\n",
    "            input_ids,\n",
    "            images=image_tensor.half().unsqueeze(0).to(\"cuda:0\"),\n",
    "            image_sizes=image_sizes,\n",
    "            do_sample=True if LLMV_TEMPERATURE > 0 else False,\n",
    "            temperature=LLMV_TEMPERATURE,\n",
    "            max_new_tokens=256,\n",
    "            use_cache=False)\n",
    "    pred_ans = tokenizer.decode(output_ids[0], skip_special_tokens=True).strip()\n",
    "    return {\"pred_ans\": pred_ans}\n",
    "\n",
    "sample = dataset[2]\n",
    "print(mmmu_eval(sample, debug=True))\n",
    "sample[\"image_1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e66921-fa4d-4ffb-98c2-587ad3557e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = \"validation\"\n",
    "\n",
    "for subject in list(MMMU_SUBJECTS_EN2RU.keys()):\n",
    "    dataset = datasets.load_dataset(\"MMMU/MMMU\", name=subject, split=split)\n",
    "    pred_dataset = dataset.map(mmmu_eval)\n",
    "    pred_dataset.save_to_disk(f\"mmmu_en_llava-v1.6-mistral-7b/{subject}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63135c8b-7fef-4045-bed6-9ab306a6fe7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
