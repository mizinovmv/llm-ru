{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78723c7d-adeb-4f2c-be0a-915b0c702667",
   "metadata": {},
   "outputs": [],
   "source": [
    "subcategories = {\n",
    "    \"abstract_algebra\": [\"math\"],\n",
    "    \"anatomy\": [\"health\"],\n",
    "    \"astronomy\": [\"physics\"],\n",
    "    \"business_ethics\": [\"business\"],\n",
    "    \"clinical_knowledge\": [\"health\"],\n",
    "    \"college_biology\": [\"biology\"],\n",
    "    \"college_chemistry\": [\"chemistry\"],\n",
    "    \"college_computer_science\": [\"computer science\"],\n",
    "    \"college_mathematics\": [\"math\"],\n",
    "    \"college_medicine\": [\"health\"],\n",
    "    \"college_physics\": [\"physics\"],\n",
    "    \"computer_security\": [\"computer science\"],\n",
    "    \"conceptual_physics\": [\"physics\"],\n",
    "    \"econometrics\": [\"economics\"],\n",
    "    \"electrical_engineering\": [\"engineering\"],\n",
    "    \"elementary_mathematics\": [\"math\"],\n",
    "    \"formal_logic\": [\"philosophy\"],\n",
    "    \"global_facts\": [\"other\"],\n",
    "    \"high_school_biology\": [\"biology\"],\n",
    "    \"high_school_chemistry\": [\"chemistry\"],\n",
    "    \"high_school_computer_science\": [\"computer science\"],\n",
    "    \"high_school_european_history\": [\"history\"],\n",
    "    \"high_school_geography\": [\"geography\"],\n",
    "    \"high_school_government_and_politics\": [\"politics\"],\n",
    "    \"high_school_macroeconomics\": [\"economics\"],\n",
    "    \"high_school_mathematics\": [\"math\"],\n",
    "    \"high_school_microeconomics\": [\"economics\"],\n",
    "    \"high_school_physics\": [\"physics\"],\n",
    "    \"high_school_psychology\": [\"psychology\"],\n",
    "    \"high_school_statistics\": [\"math\"],\n",
    "    \"high_school_us_history\": [\"history\"],\n",
    "    \"high_school_world_history\": [\"history\"],\n",
    "    \"human_aging\": [\"health\"],\n",
    "    \"human_sexuality\": [\"culture\"],\n",
    "    \"international_law\": [\"law\"],\n",
    "    \"jurisprudence\": [\"law\"],\n",
    "    \"logical_fallacies\": [\"philosophy\"],\n",
    "    \"machine_learning\": [\"computer science\"],\n",
    "    \"management\": [\"business\"],\n",
    "    \"marketing\": [\"business\"],\n",
    "    \"medical_genetics\": [\"health\"],\n",
    "    \"miscellaneous\": [\"other\"],\n",
    "    \"moral_disputes\": [\"philosophy\"],\n",
    "    \"moral_scenarios\": [\"philosophy\"],\n",
    "    \"nutrition\": [\"health\"],\n",
    "    \"philosophy\": [\"philosophy\"],\n",
    "    \"prehistory\": [\"history\"],\n",
    "    \"professional_accounting\": [\"other\"],\n",
    "    \"professional_law\": [\"law\"],\n",
    "    \"professional_medicine\": [\"health\"],\n",
    "    \"professional_psychology\": [\"psychology\"],\n",
    "    \"public_relations\": [\"politics\"],\n",
    "    \"security_studies\": [\"politics\"],\n",
    "    \"sociology\": [\"culture\"],\n",
    "    \"us_foreign_policy\": [\"politics\"],\n",
    "    \"virology\": [\"health\"],\n",
    "    \"world_religions\": [\"philosophy\"],\n",
    "}\n",
    "\n",
    "categories = {\n",
    "    \"STEM\": [\"physics\", \"chemistry\", \"biology\", \"computer science\", \"math\", \"engineering\"],\n",
    "    \"humanities\": [\"history\", \"philosophy\", \"law\"],\n",
    "    \"social sciences\": [\"politics\", \"culture\", \"economics\", \"geography\", \"psychology\"],\n",
    "    \"other (business, health, misc.)\": [\"other\", \"business\", \"health\"],\n",
    "}\n",
    "\n",
    "# in the form to fit the prompt headline\n",
    "subcategories_en2ru = {\n",
    "    \"abstract_algebra\": \"абстрактной_алгебре\",\n",
    "    \"anatomy\": \"анатомии\",\n",
    "    \"astronomy\": \"астрономии\",\n",
    "    \"business_ethics\": \"деловой_этике\",\n",
    "    \"clinical_knowledge\": \"медицинским_знаниям\",\n",
    "    \"college_biology\": \"биологии_в_вузе\",\n",
    "    \"college_chemistry\": \"химии_в_вузе\",\n",
    "    \"college_computer_science\": \"компьютерным_наукам_в_вузе\",\n",
    "    \"college_mathematics\": \"математике_в_вузе\",\n",
    "    \"college_medicine\": \"медицине_в_вузе\",\n",
    "    \"college_physics\": \"физике_в_вузе\",\n",
    "    \"computer_security\": \"компьютерной_безопасности\",\n",
    "    \"conceptual_physics\": \"теоретической_физике\",\n",
    "    \"econometrics\": \"эконометрике\",\n",
    "    \"electrical_engineering\": \"электротехнике\",\n",
    "    \"elementary_mathematics\": \"элементарной_математике\",\n",
    "    \"formal_logic\": \"формальной_логике\",\n",
    "    \"global_facts\": \"фактам_о_мире\",\n",
    "    \"high_school_biology\": \"биологии_в_старшей_школе\",\n",
    "    \"high_school_chemistry\": \"химии_в_старшей_школе\",\n",
    "    \"high_school_computer_science\": \"информатике_в_старшей_школе\",\n",
    "    \"high_school_european_history\": \"истории_Европы_в_старшей_школе\",\n",
    "    \"high_school_geography\": \"географии_в_старшей_школе\",\n",
    "    \"high_school_government_and_politics\": \"государству_и_политике_в_старшей_школе\",\n",
    "    \"high_school_macroeconomics\": \"макроэкономике_в_старшей_школе\",\n",
    "    \"high_school_mathematics\": \"математике_в_старшей_школе\",\n",
    "    \"high_school_microeconomics\": \"микроэкономике_в_старшей_школе\",\n",
    "    \"high_school_physics\": \"физике_в_старшей_школе\",\n",
    "    \"high_school_psychology\": \"психологии_в_старшей_школе\",\n",
    "    \"high_school_statistics\": \"статистике_в_старшей_школе\",\n",
    "    \"high_school_us_history\": \"истории_США_в_старшей_школе\",\n",
    "    \"high_school_world_history\": \"всемирной_истории_в_старшей_школе\",\n",
    "    \"human_aging\": \"старению_человека\",\n",
    "    \"human_sexuality\": \"человеческой_сексуальности\",\n",
    "    \"international_law\": \"международному_праву\",\n",
    "    \"jurisprudence\": \"юриспруденции\",\n",
    "    \"logical_fallacies\": \"логическим_ошибкам\",\n",
    "    \"machine_learning\": \"машинному_обучению\",\n",
    "    \"management\": \"менеджменту\",\n",
    "    \"marketing\": \"маркетингу\",\n",
    "    \"medical_genetics\": \"медицинской_генетике\",\n",
    "    \"miscellaneous\": \"разным_темам\",\n",
    "    \"moral_disputes\": \"нравственным_спорам\",\n",
    "    \"moral_scenarios\": \"нравственным_сценариям\",\n",
    "    \"nutrition\": \"правильному_питанию\",\n",
    "    \"philosophy\": \"философии\",\n",
    "    \"prehistory\": \"доисторической_эпохе\",\n",
    "    \"professional_accounting\": \"профессиональному_бухгалтерскому_учету\",\n",
    "    \"professional_law\": \"профессиональному_праву\",\n",
    "    \"professional_medicine\": \"профессиональной_медицине\",\n",
    "    \"professional_psychology\": \"профессиональной_психологии\",\n",
    "    \"public_relations\": \"связям_с_общественностью\",\n",
    "    \"security_studies\": \"исследованиям_в_области_безопасности\",\n",
    "    \"sociology\": \"социологии\",\n",
    "    \"us_foreign_policy\": \"внешней_политике_США\",\n",
    "    \"virology\": \"вирусологии\",\n",
    "    \"world_religions\": \"мировым_религиям\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a48491ed-f0c6-4250-a422-ebec70877624",
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc\n",
    "import typing as tp\n",
    "\n",
    "class Conversation(abc.ABC):\n",
    "    \"\"\"\n",
    "    Inspired by https://github.com/lm-sys/FastChat/blob/main/fastchat/conversation.py\n",
    "    \"\"\"\n",
    "    def __init__(self, system_prompt: str, roles: tp.Tuple[str, str]):\n",
    "        self.system_prompt = system_prompt\n",
    "        self.roles = roles\n",
    "        self.messages: tp.List[tp.Tuple[str, str]] = []\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def get_prompt(self) -> str:\n",
    "        pass\n",
    "\n",
    "    def update_last_message(self, text: str) -> None:\n",
    "        self.messages[-1] = (self.messages[-1][0], text)\n",
    "\n",
    "    def append_message(self, role: str, text: str) -> None:\n",
    "        self.messages.append([role, text])\n",
    "\n",
    "class EmptyConversation(Conversation):\n",
    "\n",
    "    #\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n{instruction}\\n\\n### Response:\"\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            system_prompt=\"\",\n",
    "            roles=(\"\", \"\"),\n",
    "        )\n",
    "\n",
    "    def get_prompt(self) -> str:\n",
    "        prompt = self.system_prompt\n",
    "        for role, text in self.messages:\n",
    "            if text:\n",
    "                prompt += f\"{role}{text}\"\n",
    "            else:\n",
    "                prompt += f\"{role}\"\n",
    "        return prompt\n",
    "\n",
    "conversation_classes = {\n",
    "    \"empy_prompt_conv\": EmptyConversation,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc89932c-5691-4a3c-b809-5ee3e5788d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-09-08 08:09:43,768] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import pathlib\n",
    "import typing as tp\n",
    "\n",
    "import pandas as pd\n",
    "import datasets\n",
    "import peft\n",
    "import transformers\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "LANGUAGE_CONFIG: tp.Dict[str, tp.Dict[str, str]] = {\n",
    "    \"en\": {\n",
    "        \"headline_prefix\": \"The following are multiple choice questions (with answers) about\",\n",
    "        \"answer_prefix\": \"Answer:\",\n",
    "    },\n",
    "    \"ru\": {\n",
    "        \"headline_prefix\": \"Ниже приведены вопросы с множественным выбором (с ответами) по\",\n",
    "        \"answer_prefix\": \"Ответ:\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf49c5db-1a0a-4972-969b-fdaace80bc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_in_hendrycks_format(subject: str, split: str, lang: str) -> pd.DataFrame:\n",
    "    dataset = datasets.load_dataset(\"NLPCoreTeam/mmlu_ru\", name=subject, split=split, use_auth_token=True)\n",
    "    wanted_cols = {\n",
    "        \"en\": [\"question_en\", \"choices_en\", \"answer\"],\n",
    "        \"ru\": [\"question_ru\", \"choices_ru\", \"answer\"],\n",
    "    }[lang]\n",
    "    df = dataset.to_pandas()[wanted_cols]\n",
    "    int2str = dataset.features[\"answer\"].int2str\n",
    "    df[df.columns[2]] = df[df.columns[2]].apply(lambda x: int2str(x))\n",
    "    df = pd.concat([\n",
    "        df[[df.columns[0]]],\n",
    "        pd.DataFrame(df[df.columns[1]].tolist()),\n",
    "        df[[df.columns[2]]],\n",
    "    ], axis=1)\n",
    "    df.columns = range(len(df.columns))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f72bdba4-05e7-4fd4-90d0-038b7ce1a930",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"TheBloke/Llama-2-70B-GPTQ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "259d895a-c5af-4031-994d-ceccafb10425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch 2.0.1+cu118\n",
      "transformers 4.33.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9041115eec8e44b9adf31f1650454575",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)der_True/config.json:   0%|          | 0.00/840 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50e636eb492e4f3f94b3f6352d55d20d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/40.7G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9064d3beb12444128a2d23bdaee6d046",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 8192, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-79): 80 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "          (k_proj): QuantLinear()\n",
       "          (o_proj): QuantLinear()\n",
       "          (q_proj): QuantLinear()\n",
       "          (v_proj): QuantLinear()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (act_fn): SiLUActivation()\n",
       "          (down_proj): QuantLinear()\n",
       "          (gate_proj): QuantLinear()\n",
       "          (up_proj): QuantLinear()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=8192, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import bitsandbytes as bnb\n",
    "print(\"torch\", torch.__version__)\n",
    "print(\"transformers\", transformers.__version__)\n",
    "\n",
    "git_branch = \"gptq-4bit-32g-actorder_True\"\n",
    "device_map = \"auto\"\n",
    "max_memory = None\n",
    "max_memory = {0:\"20GiB\", 1: \"22GiB\"}\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    revision=git_branch,\n",
    "    trust_remote_code=True,\n",
    "    device_map=device_map,\n",
    "    max_memory=max_memory,\n",
    ")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1673878a-3eb4-4421-a7f5-f21787faed8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c52bb7ff26be48d598f1b8a44fcb6527",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/745 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "358f49e5a9a4410c8d1dcdfc27cb96aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3999872d07724789ab0283261426720c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/411 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "LlamaTokenizer(name_or_path='TheBloke/Llama-2-70B-GPTQ', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'pad_token': '</s>'}, clean_up_tokenization_spaces=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=False)\n",
    "tokenizer.add_special_tokens({\n",
    "    \"eos_token\": tokenizer.convert_ids_to_tokens(model.config.eos_token_id),\n",
    "    \"bos_token\": tokenizer.convert_ids_to_tokens(model.config.bos_token_id),\n",
    "})\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81eff76c-d0ac-4f92-81e6-1ebce44e822e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_subject(subject: str) -> str:\n",
    "    l = subject.split(\"_\")\n",
    "    s = \"\"\n",
    "    for entry in l:\n",
    "        s += \" \" + entry\n",
    "    return s.strip()\n",
    "\n",
    "def get_pretty_subject(subject: str, lang: str) -> str:\n",
    "    return format_subject({\n",
    "        \"en\": subject,\n",
    "        \"ru\": subcategories_en2ru[subject],  # predefined map\n",
    "    }[lang])\n",
    "\n",
    "def get_prompt_from_dataframes(dev_df: pd.DataFrame, test_df: pd.DataFrame,\n",
    "                               k: int, test_iloc_idx: int, lang: str, subject: str, conversation_type: str):\n",
    "    assert 0 <= k <= 5\n",
    "    headline_prefix = LANGUAGE_CONFIG[lang][\"headline_prefix\"]\n",
    "    headline_postfix = get_pretty_subject(subject=subject, lang=lang)\n",
    "    headline = f\"{headline_prefix} {headline_postfix}.\\n\\n\"\n",
    "\n",
    "    answer_prefix = LANGUAGE_CONFIG[lang][\"answer_prefix\"]\n",
    "\n",
    "    conv = conversation_classes[conversation_type]()\n",
    "\n",
    "    is_already_taken_headline = False\n",
    "    for row_idx, row in dev_df.head(k).iterrows():\n",
    "        q = row[0]\n",
    "        options = row[1:5].tolist()\n",
    "        lettered_options = [f\"{x}. {y}\" for x, y in zip([\"A\", \"B\", \"C\", \"D\"], options)]\n",
    "        q_with_lettered_options = \"\\n\".join([q] + lettered_options)\n",
    "        if row_idx == 0:\n",
    "            q_with_lettered_options = headline + q_with_lettered_options\n",
    "            is_already_taken_headline = True\n",
    "        conv.append_message(conv.roles[0], q_with_lettered_options)\n",
    "        a = row[5]\n",
    "        \n",
    "        # if is not instruct, needed to be manually separated for mmlu examples\n",
    "        if conv.roles == (\"\", \"\"):\n",
    "            conv.append_message(conv.roles[1], f\"\\n{answer_prefix}{a}\\n\\n\")\n",
    "        else:\n",
    "            conv.append_message(conv.roles[1], f\"\\n{answer_prefix}{a}\")\n",
    "\n",
    "    row = test_df.iloc[test_iloc_idx]\n",
    "    q = row[0]\n",
    "    options = row[1:5].tolist()\n",
    "    lettered_options = [f\"{x}. {y}\" for x, y in zip([\"A\", \"B\", \"C\", \"D\"], options)]\n",
    "    q_with_lettered_options = \"\\n\".join([q] + lettered_options)\n",
    "    if not is_already_taken_headline:\n",
    "        q_with_lettered_options = headline + q_with_lettered_options\n",
    "        is_already_taken_headline = True\n",
    "    conv.append_message(conv.roles[0], q_with_lettered_options)\n",
    "    a = row[5]\n",
    "    conv.append_message(conv.roles[1], None)\n",
    "    \n",
    "    prompt = f\"{conv.get_prompt()}{answer_prefix}\"\n",
    "    return prompt\n",
    "\n",
    "def calculate_token_interest_probs(\n",
    "    input_prompt: str,\n",
    "    tokenizer: transformers.PreTrainedTokenizerBase,\n",
    "    model: tp.Union[transformers.PreTrainedModel, peft.peft_model.PeftModelForCausalLM],\n",
    ") -> tp.Dict[str, float]:\n",
    "    assert isinstance(input_prompt, str)\n",
    "    input_ids = tokenizer(input_prompt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids)\n",
    "    logits = outputs.logits  # shape (batch_size, sequence_length, vocab_size)\n",
    "    next_token_logits = logits[:, -1, :]  # shape (batch_size, vocab_size)\n",
    "\n",
    "    next_token_logits = next_token_logits.flatten()\n",
    "    assert next_token_logits.shape == torch.Size((model.config.vocab_size, ))\n",
    "\n",
    "    next_token_probs = torch.nn.functional.softmax(next_token_logits, dim=-1).cpu()  # all probs over vocab\n",
    "    # assert torch.isclose(next_token_probs.sum(), torch.tensor(1.0).to(next_token_probs.dtype), atol=1e-03)  # dtype for half/nothalf, -03 for float16\n",
    "    \n",
    "    tokens_of_interest = [\n",
    "        tokenizer(\"A\", add_special_tokens=False).input_ids[-1],\n",
    "        tokenizer(\"B\", add_special_tokens=False).input_ids[-1],\n",
    "        tokenizer(\"C\", add_special_tokens=False).input_ids[-1],\n",
    "        tokenizer(\"D\", add_special_tokens=False).input_ids[-1],\n",
    "    ]\n",
    "    \n",
    "    probs = next_token_probs[tokens_of_interest].tolist()\n",
    "    res = dict(zip([\"A\", \"B\", \"C\", \"D\"], probs))\n",
    "    return res\n",
    "\n",
    "def append_to_jsonl(data: list, filename: str) -> None:\n",
    "    with open(filename, \"a\") as f:\n",
    "        f.write(json.dumps(data) + \"\\n\")\n",
    "\n",
    "def evaluate_subject(\n",
    "    subject: str,\n",
    "    lang: str,\n",
    "    k_shot: int,\n",
    "    jsonl_filepath: str,\n",
    "    maxlen: int,\n",
    "    convtype: str,\n",
    "    tokenizer: transformers.PreTrainedTokenizerBase,\n",
    "    model: tp.Union[transformers.PreTrainedModel, peft.peft_model.PeftModelForCausalLM],\n",
    ") -> None:\n",
    "\n",
    "    dev_df = get_df_in_hendrycks_format(subject=subject, split=\"dev\", lang=lang)\n",
    "    test_df = get_df_in_hendrycks_format(subject=subject, split=\"test\", lang=lang)\n",
    "\n",
    "    for idx, row in tqdm(test_df.iterrows(), total=len(test_df), desc=subject):\n",
    "\n",
    "        current_k_shot = k_shot\n",
    "        skip_too_lengthy = False\n",
    "        while True:\n",
    "            if current_k_shot < 0:\n",
    "                logger.info(\"Skip too lengthy.\")\n",
    "                skip_too_lengthy = True\n",
    "                break\n",
    "            input_prompt = get_prompt_from_dataframes(\n",
    "                dev_df=dev_df,\n",
    "                test_df=test_df,\n",
    "                k=current_k_shot,\n",
    "                test_iloc_idx=idx,\n",
    "                lang=lang,\n",
    "                subject=subject,\n",
    "                conversation_type=convtype,\n",
    "            )\n",
    "            input_ids = tokenizer(input_prompt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "            if input_ids.shape[-1] > maxlen and current_k_shot >= 0:\n",
    "                logger.info(\"Takes smaller current_k_shot since maxlen.\")\n",
    "                current_k_shot -= 1\n",
    "            elif current_k_shot < 0:\n",
    "                logger.info(\"Skip too lengthy.\")\n",
    "                skip_too_lengthy = True\n",
    "            else:\n",
    "                break\n",
    "        if skip_too_lengthy:\n",
    "            continue\n",
    "\n",
    "        label = row[5]\n",
    "\n",
    "        preds = calculate_token_interest_probs(\n",
    "            input_prompt=input_prompt,\n",
    "            tokenizer=tokenizer,\n",
    "            model=model,\n",
    "        )\n",
    "\n",
    "        append_to_jsonl(data=[input_prompt, label, preds], filename=jsonl_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3935963-d5d7-4b60-b69c-08436870a4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset mmlu_ru (/home/mmv/.cache/huggingface/datasets/NLPCoreTeam___mmlu_ru/abstract_algebra/1.0.0/5f8c605caf405b545e54fa796577e79a3fa9fc757b9842bd4eb911133dcf5b8b)\n",
      "WARNING:datasets.builder:Found cached dataset mmlu_ru (/home/mmv/.cache/huggingface/datasets/NLPCoreTeam___mmlu_ru/abstract_algebra/1.0.0/5f8c605caf405b545e54fa796577e79a3fa9fc757b9842bd4eb911133dcf5b8b)\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1535: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ниже приведены вопросы с множественным выбором (с ответами) по абстрактной алгебре.\n",
      "\n",
      "Найдите все c в Z_3 таким образом, чтобы Z_3[x]/(x ^ 2 + c) было полем.\n",
      "A. 0\n",
      "B. 1\n",
      "C. 2\n",
      "D. 3\n",
      "Ответ:B\n",
      "\n",
      "Утверждение 1 | Если aH является элементом факторной группы, то |aH| делит |a|. Утверждение 2 | Если H и K являются подгруппами G, то HK является подгруппой G.\n",
      "A. Верно, верно\n",
      "B. Ложь, ложь\n",
      "C. Правда, ложь\n",
      "D. Ложь, истина\n",
      "Ответ:B\n",
      "\n",
      "Утверждение 1 | Каждый элемент группы порождает циклическую подгруппу группы. Утверждение 2 | Симметричная группа S_10 состоит из 10 элементов.\n",
      "A. Верно, верно\n",
      "B. Ложь, ложь\n",
      "C. Правда, ложь\n",
      "D. Ложь, истина\n",
      "Ответ:C\n",
      "\n",
      "Утверждение 1| Каждая функция из конечного множества на саму себя должна быть один к одному. Утверждение 2 | Каждая подгруппа абелевой группы является абелевой.\n",
      "A. Верно, верно\n",
      "B. Ложь, ложь\n",
      "C. Правда, ложь\n",
      "D. Ложь, истина\n",
      "Ответ:A\n",
      "\n",
      "Найдите характеристику кольца 2Z.\n",
      "A. 0\n",
      "B. 3\n",
      "C. 12\n",
      "D. 30\n",
      "Ответ:A\n",
      "\n",
      "Найдите степень для данного расширения поля Q(sqrt(2), sqrt(3), sqrt(18)) над Q.\n",
      "A. 0\n",
      "B. 4\n",
      "C. 2\n",
      "D. 6Ответ:\n",
      "CPU times: user 2.5 s, sys: 479 ms, total: 2.98 s\n",
      "Wall time: 6.22 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<s>Ниже приведены вопросы с множественным выбором (с ответами) по абстрактной алгебре.\\n\\nНайдите все c в Z_3 таким образом, чтобы Z_3[x]/(x ^ 2 + c) было полем.\\nA. 0\\nB. 1\\nC. 2\\nD. 3\\nОтвет:B\\n\\nУтверждение 1 | Если aH является элементом факторной группы, то |aH| делит |a|. Утверждение 2 | Если H и K являются подгруппами G, то HK является подгруппой G.\\nA. Верно, верно\\nB. Ложь, ложь\\nC. Правда, ложь\\nD. Ложь, истина\\nОтвет:B\\n\\nУтверждение 1 | Каждый элемент группы порождает циклическую подгруппу группы. Утверждение 2 | Симметричная группа S_10 состоит из 10 элементов.\\nA. Верно, верно\\nB. Ложь, ложь\\nC. Правда, ложь\\nD. Ложь, истина\\nОтвет:C\\n\\nУтверждение 1| Каждая функция из конечного множества на саму себя должна быть один к одному. Утверждение 2 | Каждая подгруппа абелевой группы является абелевой.\\nA. Верно, верно\\nB. Ложь, ложь\\nC. Правда, ложь\\nD. Ложь, истина\\nОтвет:A\\n\\nНайдите характеристику кольца 2Z.\\nA. 0\\nB. 3\\nC. 12\\nD. 30\\nОтвет:A\\n\\nНайдите степень для данного расширения поля Q(sqrt(2), sqrt(3), sqrt(18)) над Q.\\nA. 0\\nB. 4\\nC. 2\\nD. 6Ответ:D\\n\\nНайдите характеристи'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "lang = \"ru\"\n",
    "subject = \"abstract_algebra\"\n",
    "convtype = \"empy_prompt_conv\"\n",
    "current_k_shot = 5\n",
    "idx = 0\n",
    "dev_df = get_df_in_hendrycks_format(subject=subject, split=\"dev\", lang=lang)\n",
    "test_df = get_df_in_hendrycks_format(subject=subject, split=\"test\", lang=lang)\n",
    "input_prompt = get_prompt_from_dataframes(\n",
    "    dev_df=dev_df,\n",
    "                test_df=test_df,\n",
    "                k=current_k_shot,\n",
    "                test_iloc_idx=idx,\n",
    "                lang=lang,\n",
    "                subject=subject,\n",
    "                conversation_type=convtype,\n",
    "            )\n",
    "print(input_prompt)\n",
    "input_ids = tokenizer(\n",
    "    input_prompt,\n",
    "    return_tensors=\"pt\",\n",
    "    return_token_type_ids=False,\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    ")['input_ids']\n",
    "output_ids = model.generate(input_ids, max_new_tokens=10)\n",
    "ouput_str = tokenizer.decode(output_ids[0])\n",
    "ouput_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8e07f7-1edf-4ecf-a86c-ecee3959fe01",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"mmlu_ru_Llama-2-70B-GPTQ\"\n",
    "lang = \"ru\"\n",
    "k_shot = 5\n",
    "maxlen = 2048\n",
    "convtype = \"empy_prompt_conv\"\n",
    "\n",
    "subjects = list(subcategories.keys())\n",
    "for each_subject in subjects:\n",
    "    jsonl_filepath = str(pathlib.Path(output_dir) / f\"{each_subject}.jsonl\")\n",
    "    pathlib.Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "    logger.info(f\"Filepath JSONL: {jsonl_filepath}\")\n",
    "    if pathlib.Path(jsonl_filepath).exists():\n",
    "        logger.info(f\"File already exists! Please manually verify that it wasn't partially interrupted.\")\n",
    "        continue\n",
    "    evaluate_subject(\n",
    "            subject=each_subject,\n",
    "            lang=lang,\n",
    "            k_shot=k_shot,\n",
    "            jsonl_filepath=jsonl_filepath,\n",
    "            maxlen=maxlen, convtype=convtype,\n",
    "            tokenizer=tokenizer,\n",
    "            model=model,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cafd3203-0f79-434e-8466-7e67c9c4b475",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"mmlu_ru_Llama-2-70B-GPTQ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc0ae2ce-8cce-4b80-a940-70caa34f3d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mmlu_ru_Llama-2-70B-GPTQ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60.205311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mmlu_ru_Llama-2-70B-GPTQ\n",
       "0                 60.205311"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "category_to_main_category = {value: key for key, sublist in categories.items() for value in sublist}\n",
    "subcategories2categories = {key: category_to_main_category[value[0]] for key, value in subcategories.items()}\n",
    "\n",
    "def calculate_accuracy_from_directory(dirpath: str) -> tp.Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    assert pathlib.Path(dirpath).exists()\n",
    "    filepaths = [str(x) for x in pathlib.Path(dirpath).glob('*.jsonl')]\n",
    "    # assert len(filepaths) == 57\n",
    "    res = {}\n",
    "    for each_filepath in filepaths:\n",
    "        df = pd.read_json(each_filepath, lines=True)\n",
    "        df.columns = ['prompt', 'label', 'preds']\n",
    "        cors = []\n",
    "        for idx, row in df.iterrows():\n",
    "            preds = row['preds']\n",
    "            best_idx = np.argmax(list(preds.values()))\n",
    "            y_pred = list(preds.keys())[best_idx]\n",
    "            y_true = row['label']\n",
    "            y_pred = y_pred.strip()\n",
    "            y_true = y_true.strip()\n",
    "            cors.append(y_true == y_pred)\n",
    "        acc = np.mean(cors)\n",
    "        res[pathlib.Path(each_filepath).stem] = acc * 100\n",
    "    \n",
    "    df = pd.DataFrame({pathlib.Path(dirpath).stem: res}).reset_index()\n",
    "    df = df.rename(columns={'index': 'subcategory'})\n",
    "    subcategories_df = df.copy()\n",
    "    \n",
    "    df = subcategories_df.copy()\n",
    "    df['subcategory'] = df['subcategory'].map(subcategories2categories)\n",
    "    df = df.rename(columns={'subcategory': 'category'})\n",
    "    df = df.groupby('category').mean().reset_index()\n",
    "    categories_df = df.copy()\n",
    "    \n",
    "    total_df = pd.DataFrame({pathlib.Path(dirpath).stem: [categories_df[pathlib.Path(dirpath).stem].mean()]})\n",
    "    \n",
    "    # assert subcategories_df.shape == (57, 2)\n",
    "    # assert categories_df.shape == (4, 2)\n",
    "    # assert total_df.shape == (1, 1)\n",
    "    return (subcategories_df, categories_df, total_df)\n",
    "\n",
    "subcategories_df, categories_df, total_df = calculate_accuracy_from_directory(dirpath=output_dir)\n",
    "print(total_df.shape)\n",
    "total_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ea70f8f-336c-4b32-98c0-5c0b81210a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>mmlu_ru_Llama-2-70B-GPTQ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>STEM</td>\n",
       "      <td>49.651062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>humanities</td>\n",
       "      <td>66.031919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>other (business, health, misc.)</td>\n",
       "      <td>58.215279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>social sciences</td>\n",
       "      <td>66.922983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          category  mmlu_ru_Llama-2-70B-GPTQ\n",
       "0                             STEM                 49.651062\n",
       "1                       humanities                 66.031919\n",
       "2  other (business, health, misc.)                 58.215279\n",
       "3                  social sciences                 66.922983"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c61a104-ac1e-4925-ab32-6221d3124e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subcategory</th>\n",
       "      <th>mmlu_ru_Llama-2-70B-GPTQ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abstract_algebra</td>\n",
       "      <td>33.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anatomy</td>\n",
       "      <td>53.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>astronomy</td>\n",
       "      <td>70.394737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business_ethics</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>clinical_knowledge</td>\n",
       "      <td>57.358491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>college_biology</td>\n",
       "      <td>61.805556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>college_chemistry</td>\n",
       "      <td>43.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>college_computer_science</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>college_mathematics</td>\n",
       "      <td>34.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>college_medicine</td>\n",
       "      <td>50.289017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>college_physics</td>\n",
       "      <td>32.352941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>computer_security</td>\n",
       "      <td>72.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>conceptual_physics</td>\n",
       "      <td>57.021277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>econometrics</td>\n",
       "      <td>33.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>electrical_engineering</td>\n",
       "      <td>53.103448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>elementary_mathematics</td>\n",
       "      <td>37.301587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>formal_logic</td>\n",
       "      <td>40.476190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>global_facts</td>\n",
       "      <td>46.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>high_school_biology</td>\n",
       "      <td>72.580645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>high_school_chemistry</td>\n",
       "      <td>43.349754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>high_school_computer_science</td>\n",
       "      <td>72.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>high_school_european_history</td>\n",
       "      <td>73.939394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>high_school_geography</td>\n",
       "      <td>76.262626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>high_school_government_and_politics</td>\n",
       "      <td>78.238342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>high_school_macroeconomics</td>\n",
       "      <td>61.794872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>high_school_mathematics</td>\n",
       "      <td>31.481481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>high_school_microeconomics</td>\n",
       "      <td>62.184874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>high_school_physics</td>\n",
       "      <td>39.735099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>high_school_psychology</td>\n",
       "      <td>71.926606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>high_school_statistics</td>\n",
       "      <td>55.092593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>high_school_us_history</td>\n",
       "      <td>78.921569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>high_school_world_history</td>\n",
       "      <td>78.481013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>human_aging</td>\n",
       "      <td>67.264574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>human_sexuality</td>\n",
       "      <td>64.122137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>international_law</td>\n",
       "      <td>83.471074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>jurisprudence</td>\n",
       "      <td>64.814815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>logical_fallacies</td>\n",
       "      <td>65.644172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>machine_learning</td>\n",
       "      <td>37.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>management</td>\n",
       "      <td>70.873786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>marketing</td>\n",
       "      <td>78.632479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>medical_genetics</td>\n",
       "      <td>49.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>miscellaneous</td>\n",
       "      <td>68.710089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>moral_disputes</td>\n",
       "      <td>68.786127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>moral_scenarios</td>\n",
       "      <td>39.217877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>nutrition</td>\n",
       "      <td>65.032680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>philosophy</td>\n",
       "      <td>69.453376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>prehistory</td>\n",
       "      <td>67.901235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>professional_accounting</td>\n",
       "      <td>42.198582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>professional_law</td>\n",
       "      <td>45.436767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>professional_medicine</td>\n",
       "      <td>53.308824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>professional_psychology</td>\n",
       "      <td>60.947712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>public_relations</td>\n",
       "      <td>62.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>security_studies</td>\n",
       "      <td>71.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>sociology</td>\n",
       "      <td>78.109453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>us_foreign_policy</td>\n",
       "      <td>82.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>virology</td>\n",
       "      <td>53.012048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>world_religions</td>\n",
       "      <td>81.871345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            subcategory  mmlu_ru_Llama-2-70B-GPTQ\n",
       "0                      abstract_algebra                 33.000000\n",
       "1                               anatomy                 53.333333\n",
       "2                             astronomy                 70.394737\n",
       "3                       business_ethics                 60.000000\n",
       "4                    clinical_knowledge                 57.358491\n",
       "5                       college_biology                 61.805556\n",
       "6                     college_chemistry                 43.000000\n",
       "7              college_computer_science                 48.000000\n",
       "8                   college_mathematics                 34.000000\n",
       "9                      college_medicine                 50.289017\n",
       "10                      college_physics                 32.352941\n",
       "11                    computer_security                 72.000000\n",
       "12                   conceptual_physics                 57.021277\n",
       "13                         econometrics                 33.333333\n",
       "14               electrical_engineering                 53.103448\n",
       "15               elementary_mathematics                 37.301587\n",
       "16                         formal_logic                 40.476190\n",
       "17                         global_facts                 46.000000\n",
       "18                  high_school_biology                 72.580645\n",
       "19                high_school_chemistry                 43.349754\n",
       "20         high_school_computer_science                 72.000000\n",
       "21         high_school_european_history                 73.939394\n",
       "22                high_school_geography                 76.262626\n",
       "23  high_school_government_and_politics                 78.238342\n",
       "24           high_school_macroeconomics                 61.794872\n",
       "25              high_school_mathematics                 31.481481\n",
       "26           high_school_microeconomics                 62.184874\n",
       "27                  high_school_physics                 39.735099\n",
       "28               high_school_psychology                 71.926606\n",
       "29               high_school_statistics                 55.092593\n",
       "30               high_school_us_history                 78.921569\n",
       "31            high_school_world_history                 78.481013\n",
       "32                          human_aging                 67.264574\n",
       "33                      human_sexuality                 64.122137\n",
       "34                    international_law                 83.471074\n",
       "35                        jurisprudence                 64.814815\n",
       "36                    logical_fallacies                 65.644172\n",
       "37                     machine_learning                 37.500000\n",
       "38                           management                 70.873786\n",
       "39                            marketing                 78.632479\n",
       "40                     medical_genetics                 49.000000\n",
       "41                        miscellaneous                 68.710089\n",
       "42                       moral_disputes                 68.786127\n",
       "43                      moral_scenarios                 39.217877\n",
       "44                            nutrition                 65.032680\n",
       "45                           philosophy                 69.453376\n",
       "46                           prehistory                 67.901235\n",
       "47              professional_accounting                 42.198582\n",
       "48                     professional_law                 45.436767\n",
       "49                professional_medicine                 53.308824\n",
       "50              professional_psychology                 60.947712\n",
       "51                     public_relations                 62.727273\n",
       "52                     security_studies                 71.428571\n",
       "53                            sociology                 78.109453\n",
       "54                    us_foreign_policy                 82.000000\n",
       "55                             virology                 53.012048\n",
       "56                      world_religions                 81.871345"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subcategories_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f517bb-a706-4baf-8e51-bc17a70af3be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aaea0ec-c3b1-4748-8cea-8bc6a611642c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
