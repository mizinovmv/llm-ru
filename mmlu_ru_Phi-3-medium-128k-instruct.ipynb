{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a5146af-3d1a-4922-8906-cda830e5894e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78723c7d-adeb-4f2c-be0a-915b0c702667",
   "metadata": {},
   "outputs": [],
   "source": [
    "subcategories = {\n",
    "    \"abstract_algebra\": [\"math\"],\n",
    "    \"anatomy\": [\"health\"],\n",
    "    \"astronomy\": [\"physics\"],\n",
    "    \"business_ethics\": [\"business\"],\n",
    "    \"clinical_knowledge\": [\"health\"],\n",
    "    \"college_biology\": [\"biology\"],\n",
    "    \"college_chemistry\": [\"chemistry\"],\n",
    "    \"college_computer_science\": [\"computer science\"],\n",
    "    \"college_mathematics\": [\"math\"],\n",
    "    \"college_medicine\": [\"health\"],\n",
    "    \"college_physics\": [\"physics\"],\n",
    "    \"computer_security\": [\"computer science\"],\n",
    "    \"conceptual_physics\": [\"physics\"],\n",
    "    \"econometrics\": [\"economics\"],\n",
    "    \"electrical_engineering\": [\"engineering\"],\n",
    "    \"elementary_mathematics\": [\"math\"],\n",
    "    \"formal_logic\": [\"philosophy\"],\n",
    "    \"global_facts\": [\"other\"],\n",
    "    \"high_school_biology\": [\"biology\"],\n",
    "    \"high_school_chemistry\": [\"chemistry\"],\n",
    "    \"high_school_computer_science\": [\"computer science\"],\n",
    "    \"high_school_european_history\": [\"history\"],\n",
    "    \"high_school_geography\": [\"geography\"],\n",
    "    \"high_school_government_and_politics\": [\"politics\"],\n",
    "    \"high_school_macroeconomics\": [\"economics\"],\n",
    "    \"high_school_mathematics\": [\"math\"],\n",
    "    \"high_school_microeconomics\": [\"economics\"],\n",
    "    \"high_school_physics\": [\"physics\"],\n",
    "    \"high_school_psychology\": [\"psychology\"],\n",
    "    \"high_school_statistics\": [\"math\"],\n",
    "    \"high_school_us_history\": [\"history\"],\n",
    "    \"high_school_world_history\": [\"history\"],\n",
    "    \"human_aging\": [\"health\"],\n",
    "    \"human_sexuality\": [\"culture\"],\n",
    "    \"international_law\": [\"law\"],\n",
    "    \"jurisprudence\": [\"law\"],\n",
    "    \"logical_fallacies\": [\"philosophy\"],\n",
    "    \"machine_learning\": [\"computer science\"],\n",
    "    \"management\": [\"business\"],\n",
    "    \"marketing\": [\"business\"],\n",
    "    \"medical_genetics\": [\"health\"],\n",
    "    \"miscellaneous\": [\"other\"],\n",
    "    \"moral_disputes\": [\"philosophy\"],\n",
    "    \"moral_scenarios\": [\"philosophy\"],\n",
    "    \"nutrition\": [\"health\"],\n",
    "    \"philosophy\": [\"philosophy\"],\n",
    "    \"prehistory\": [\"history\"],\n",
    "    \"professional_accounting\": [\"other\"],\n",
    "    \"professional_law\": [\"law\"],\n",
    "    \"professional_medicine\": [\"health\"],\n",
    "    \"professional_psychology\": [\"psychology\"],\n",
    "    \"public_relations\": [\"politics\"],\n",
    "    \"security_studies\": [\"politics\"],\n",
    "    \"sociology\": [\"culture\"],\n",
    "    \"us_foreign_policy\": [\"politics\"],\n",
    "    \"virology\": [\"health\"],\n",
    "    \"world_religions\": [\"philosophy\"],\n",
    "}\n",
    "\n",
    "categories = {\n",
    "    \"STEM\": [\"physics\", \"chemistry\", \"biology\", \"computer science\", \"math\", \"engineering\"],\n",
    "    \"humanities\": [\"history\", \"philosophy\", \"law\"],\n",
    "    \"social sciences\": [\"politics\", \"culture\", \"economics\", \"geography\", \"psychology\"],\n",
    "    \"other (business, health, misc.)\": [\"other\", \"business\", \"health\"],\n",
    "}\n",
    "\n",
    "# in the form to fit the prompt headline\n",
    "subcategories_en2ru = {\n",
    "    \"abstract_algebra\": \"абстрактной_алгебре\",\n",
    "    \"anatomy\": \"анатомии\",\n",
    "    \"astronomy\": \"астрономии\",\n",
    "    \"business_ethics\": \"деловой_этике\",\n",
    "    \"clinical_knowledge\": \"медицинским_знаниям\",\n",
    "    \"college_biology\": \"биологии_в_вузе\",\n",
    "    \"college_chemistry\": \"химии_в_вузе\",\n",
    "    \"college_computer_science\": \"компьютерным_наукам_в_вузе\",\n",
    "    \"college_mathematics\": \"математике_в_вузе\",\n",
    "    \"college_medicine\": \"медицине_в_вузе\",\n",
    "    \"college_physics\": \"физике_в_вузе\",\n",
    "    \"computer_security\": \"компьютерной_безопасности\",\n",
    "    \"conceptual_physics\": \"теоретической_физике\",\n",
    "    \"econometrics\": \"эконометрике\",\n",
    "    \"electrical_engineering\": \"электротехнике\",\n",
    "    \"elementary_mathematics\": \"элементарной_математике\",\n",
    "    \"formal_logic\": \"формальной_логике\",\n",
    "    \"global_facts\": \"фактам_о_мире\",\n",
    "    \"high_school_biology\": \"биологии_в_старшей_школе\",\n",
    "    \"high_school_chemistry\": \"химии_в_старшей_школе\",\n",
    "    \"high_school_computer_science\": \"информатике_в_старшей_школе\",\n",
    "    \"high_school_european_history\": \"истории_Европы_в_старшей_школе\",\n",
    "    \"high_school_geography\": \"географии_в_старшей_школе\",\n",
    "    \"high_school_government_and_politics\": \"государству_и_политике_в_старшей_школе\",\n",
    "    \"high_school_macroeconomics\": \"макроэкономике_в_старшей_школе\",\n",
    "    \"high_school_mathematics\": \"математике_в_старшей_школе\",\n",
    "    \"high_school_microeconomics\": \"микроэкономике_в_старшей_школе\",\n",
    "    \"high_school_physics\": \"физике_в_старшей_школе\",\n",
    "    \"high_school_psychology\": \"психологии_в_старшей_школе\",\n",
    "    \"high_school_statistics\": \"статистике_в_старшей_школе\",\n",
    "    \"high_school_us_history\": \"истории_США_в_старшей_школе\",\n",
    "    \"high_school_world_history\": \"всемирной_истории_в_старшей_школе\",\n",
    "    \"human_aging\": \"старению_человека\",\n",
    "    \"human_sexuality\": \"человеческой_сексуальности\",\n",
    "    \"international_law\": \"международному_праву\",\n",
    "    \"jurisprudence\": \"юриспруденции\",\n",
    "    \"logical_fallacies\": \"логическим_ошибкам\",\n",
    "    \"machine_learning\": \"машинному_обучению\",\n",
    "    \"management\": \"менеджменту\",\n",
    "    \"marketing\": \"маркетингу\",\n",
    "    \"medical_genetics\": \"медицинской_генетике\",\n",
    "    \"miscellaneous\": \"разным_темам\",\n",
    "    \"moral_disputes\": \"нравственным_спорам\",\n",
    "    \"moral_scenarios\": \"нравственным_сценариям\",\n",
    "    \"nutrition\": \"правильному_питанию\",\n",
    "    \"philosophy\": \"философии\",\n",
    "    \"prehistory\": \"доисторической_эпохе\",\n",
    "    \"professional_accounting\": \"профессиональному_бухгалтерскому_учету\",\n",
    "    \"professional_law\": \"профессиональному_праву\",\n",
    "    \"professional_medicine\": \"профессиональной_медицине\",\n",
    "    \"professional_psychology\": \"профессиональной_психологии\",\n",
    "    \"public_relations\": \"связям_с_общественностью\",\n",
    "    \"security_studies\": \"исследованиям_в_области_безопасности\",\n",
    "    \"sociology\": \"социологии\",\n",
    "    \"us_foreign_policy\": \"внешней_политике_США\",\n",
    "    \"virology\": \"вирусологии\",\n",
    "    \"world_religions\": \"мировым_религиям\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a48491ed-f0c6-4250-a422-ebec70877624",
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc\n",
    "import typing as tp\n",
    "\n",
    "class Conversation(abc.ABC):\n",
    "    \"\"\"\n",
    "    Inspired by https://github.com/lm-sys/FastChat/blob/main/fastchat/conversation.py\n",
    "    \"\"\"\n",
    "    def __init__(self, system_prompt: str, roles: tp.Tuple[str, str]):\n",
    "        self.system_prompt = system_prompt\n",
    "        self.roles = roles\n",
    "        self.messages: tp.List[tp.List[str, str]] = []\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def get_prompt(self) -> str:\n",
    "        pass\n",
    "\n",
    "    def update_last_message(self, text: str) -> None:\n",
    "        self.messages[-1] = (self.messages[-1][0], text)\n",
    "\n",
    "    def append_message(self, role: str, text: str) -> None:\n",
    "        self.messages.append({\"role\":role, \"content\":text})\n",
    "\n",
    "class EmptyConversation(Conversation):\n",
    "\n",
    "    #\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n{instruction}\\n\\n### Response:\"\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            system_prompt=\"\",\n",
    "            roles=(\"user\", \"assistant\"),\n",
    "        )\n",
    "\n",
    "    def get_prompt(self) -> str:\n",
    "        prompt = self.system_prompt\n",
    "        for m in self.messages:\n",
    "            prompt += str(m)\n",
    "        return prompt\n",
    "\n",
    "conversation_classes = {\n",
    "    \"empy_prompt_conv\": EmptyConversation,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc89932c-5691-4a3c-b809-5ee3e5788d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import pathlib\n",
    "import typing as tp\n",
    "\n",
    "import pandas as pd\n",
    "import datasets\n",
    "import peft\n",
    "import transformers\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "LANGUAGE_CONFIG: tp.Dict[str, tp.Dict[str, str]] = {\n",
    "    \"en\": {\n",
    "        \"headline_prefix\": \"The following are multiple choice questions (with answers) about\",\n",
    "        \"answer_prefix\": \"Answer:\",\n",
    "    },\n",
    "    \"ru\": {\n",
    "        \"headline_prefix\": \"Ниже приведены вопросы с множественным выбором (с ответами) по\",\n",
    "        \"answer_prefix\": \"Ответ:\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf49c5db-1a0a-4972-969b-fdaace80bc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_in_hendrycks_format(subject: str, split: str, lang: str) -> pd.DataFrame:\n",
    "    dataset = datasets.load_dataset(\"NLPCoreTeam/mmlu_ru\", name=subject, split=split)\n",
    "    wanted_cols = {\n",
    "        \"en\": [\"question_en\", \"choices_en\", \"answer\"],\n",
    "        \"ru\": [\"question_ru\", \"choices_ru\", \"answer\"],\n",
    "    }[lang]\n",
    "    df = dataset.to_pandas()[wanted_cols]\n",
    "    int2str = dataset.features[\"answer\"].int2str\n",
    "    df[df.columns[2]] = df[df.columns[2]].apply(lambda x: int2str(x))\n",
    "    df = pd.concat([\n",
    "        df[[df.columns[0]]],\n",
    "        pd.DataFrame(df[df.columns[1]].tolist()),\n",
    "        df[[df.columns[2]]],\n",
    "    ], axis=1)\n",
    "    df.columns = range(len(df.columns))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f72bdba4-05e7-4fd4-90d0-038b7ce1a930",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"../Phi-3-medium-128k-instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "259d895a-c5af-4031-994d-ceccafb10425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch 2.3.0+cu121\n",
      "transformers 4.39.3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b91b931732745c78e43cb3d1d7a53df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Phi3ForCausalLM(\n",
       "  (model): Phi3Model(\n",
       "    (embed_tokens): Embedding(32064, 5120)\n",
       "    (embed_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0-39): 40 x Phi3DecoderLayer(\n",
       "        (self_attn): Phi3FlashAttention2(\n",
       "          (o_proj): Linear(in_features=5120, out_features=5120, bias=False)\n",
       "          (qkv_proj): Linear(in_features=5120, out_features=7680, bias=False)\n",
       "          (rotary_emb): Phi3SuScaledRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Phi3MLP(\n",
       "          (gate_up_proj): Linear(in_features=5120, out_features=35840, bias=False)\n",
       "          (down_proj): Linear(in_features=17920, out_features=5120, bias=False)\n",
       "          (activation_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Phi3RMSNorm()\n",
       "        (resid_attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (resid_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (post_attention_layernorm): Phi3RMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): Phi3RMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=5120, out_features=32064, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoModelForCausalLM\n",
    "print(\"torch\", torch.__version__)\n",
    "print(\"transformers\", transformers.__version__)\n",
    "\n",
    "device_map = \"auto\"\n",
    "max_memory = {0:\"24GiB\", 1: \"24GiB\"}\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id,\n",
    "                                             trust_remote_code=True,\n",
    "                                             torch_dtype=\"auto\",\n",
    "                                             attn_implementation=\"flash_attention_2\",\n",
    "                                             device_map=device_map,\n",
    "                                             max_memory=max_memory)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f50bfe52-25dd-4007-8e4b-c5d9eaffa485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.bfloat16 13960238080 100.0\n"
     ]
    }
   ],
   "source": [
    "def model_dtypes(model):\n",
    "    # Verifying the datatypes.\n",
    "    dtypes = {}\n",
    "    for name, p in model.named_parameters():\n",
    "        dtype = p.dtype\n",
    "        if dtype not in dtypes: dtypes[dtype] = 0\n",
    "        dtypes[dtype] += p.numel()\n",
    "    total = 0\n",
    "    for k, v in dtypes.items(): total+= v\n",
    "    for k, v in dtypes.items():\n",
    "        print(k, v, v/total * 100)\n",
    "\n",
    "model_dtypes(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1673878a-3eb4-4421-a7f5-f21787faed8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LlamaTokenizerFast(name_or_path='../Phi-3-medium-128k-instruct', vocab_size=32000, model_max_length=131072, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '<|endoftext|>', 'unk_token': '<unk>', 'pad_token': '<|endoftext|>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t32000: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32001: AddedToken(\"<|assistant|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32002: AddedToken(\"<|placeholder1|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32003: AddedToken(\"<|placeholder2|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32004: AddedToken(\"<|placeholder3|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32005: AddedToken(\"<|placeholder4|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32006: AddedToken(\"<|system|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32007: AddedToken(\"<|end|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32008: AddedToken(\"<|placeholder5|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32009: AddedToken(\"<|placeholder6|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32010: AddedToken(\"<|user|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "# tokenizer.pad_token = tokenizer.unk_token  # use unk rather than eos token to prevent endless generation\n",
    "# tokenizer.pad_token_id = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81eff76c-d0ac-4f92-81e6-1ebce44e822e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_subject(subject: str) -> str:\n",
    "    l = subject.split(\"_\")\n",
    "    s = \"\"\n",
    "    for entry in l:\n",
    "        s += \" \" + entry\n",
    "    return s.strip()\n",
    "\n",
    "def get_pretty_subject(subject: str, lang: str) -> str:\n",
    "    return format_subject({\n",
    "        \"en\": subject,\n",
    "        \"ru\": subcategories_en2ru[subject],  # predefined map\n",
    "    }[lang])\n",
    "\n",
    "def get_prompt_from_dataframes(dev_df: pd.DataFrame, test_df: pd.DataFrame,\n",
    "                               k: int, test_iloc_idx: int, lang: str, subject: str, conversation_type: str):\n",
    "    assert 0 <= k <= 5\n",
    "    headline_prefix = LANGUAGE_CONFIG[lang][\"headline_prefix\"]\n",
    "    headline_postfix = get_pretty_subject(subject=subject, lang=lang)\n",
    "    headline = f\"{headline_prefix} {headline_postfix}.\\n\\n\"\n",
    "\n",
    "    answer_prefix = LANGUAGE_CONFIG[lang][\"answer_prefix\"]\n",
    "\n",
    "    conv = conversation_classes[conversation_type]()\n",
    "\n",
    "    is_already_taken_headline = False\n",
    "    for row_idx, row in dev_df.head(k).iterrows():\n",
    "        q = row[0].strip()\n",
    "        options = row[1:5].tolist()\n",
    "        lettered_options = [f\"{x}) {y}\" for x, y in zip([\"A\", \"B\", \"C\", \"D\"], options)]\n",
    "        q_with_lettered_options = \"\\n\".join([q, \"\\n\".join(lettered_options)])\n",
    "        if row_idx == 0:\n",
    "            q_with_lettered_options = headline + q_with_lettered_options\n",
    "            is_already_taken_headline = True\n",
    "        conv.append_message(conv.roles[0], q_with_lettered_options + \"\\n\\n\" + answer_prefix)\n",
    "        a = row[5]\n",
    "        \n",
    "        # if is not instruct, needed to be manually separated for mmlu examples\n",
    "        conv.append_message(conv.roles[1], f\"{a}\")\n",
    "\n",
    "    row = test_df.iloc[test_iloc_idx]\n",
    "    q = row[0]\n",
    "    options = row[1:5].tolist()\n",
    "    lettered_options = [f\"{x}) {y}\" for x, y in zip([\"A\", \"B\", \"C\", \"D\"], options)]\n",
    "    q_with_lettered_options = \"\\n\".join([q, \"\\n\".join(lettered_options)])\n",
    "    if not is_already_taken_headline:\n",
    "        q_with_lettered_options = headline + q_with_lettered_options\n",
    "        is_already_taken_headline = True\n",
    "    conv.append_message(conv.roles[0], q_with_lettered_options + \"\\n\\n\" + answer_prefix)\n",
    "    a = row[5]\n",
    "    # conv.append_message(conv.roles[1], \"\\n\" + answer_prefix)\n",
    "    # prompt = f\"{conv.get_prompt()}{answer_prefix}\"\n",
    "    return conv.messages\n",
    "\n",
    "def calculate_token_interest_probs(\n",
    "    input_ids,\n",
    "    tokenizer: transformers.PreTrainedTokenizerBase,\n",
    "    model: tp.Union[transformers.PreTrainedModel, peft.peft_model.PeftModelForCausalLM],\n",
    ") -> tp.Dict[str, float]:    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids)\n",
    "    logits = outputs.logits  # shape (batch_size, sequence_length, vocab_size)\n",
    "    next_token_logits = logits[:, -1, :]  # shape (batch_size, vocab_size)\n",
    "\n",
    "    next_token_logits = next_token_logits.flatten()\n",
    "    assert next_token_logits.shape == torch.Size((model.config.vocab_size, ))\n",
    "\n",
    "    next_token_probs = torch.nn.functional.softmax(next_token_logits, dim=-1).cpu()  # all probs over vocab\n",
    "    # assert torch.isclose(next_token_probs.sum(), torch.tensor(1.0).to(next_token_probs.dtype), atol=1e-03)  # dtype for half/nothalf, -03 for float16\n",
    "    \n",
    "    tokens_of_interest = [\n",
    "        tokenizer(\"A\", add_special_tokens=False).input_ids[-1],\n",
    "        tokenizer(\"B\", add_special_tokens=False).input_ids[-1],\n",
    "        tokenizer(\"C\", add_special_tokens=False).input_ids[-1],\n",
    "        tokenizer(\"D\", add_special_tokens=False).input_ids[-1],\n",
    "    ]\n",
    "\n",
    "    probs = next_token_probs[tokens_of_interest].tolist()\n",
    "    res = dict(zip([\"A\", \"B\", \"C\", \"D\"], probs))\n",
    "    return res\n",
    "\n",
    "def append_to_jsonl(data: list, filename: str) -> None:\n",
    "    with open(filename, \"a\") as f:\n",
    "        f.write(json.dumps(data) + \"\\n\")\n",
    "\n",
    "def evaluate_subject(\n",
    "    subject: str,\n",
    "    lang: str,\n",
    "    k_shot: int,\n",
    "    jsonl_filepath: str,\n",
    "    maxlen: int,\n",
    "    convtype: str,\n",
    "    tokenizer: transformers.PreTrainedTokenizerBase,\n",
    "    model: tp.Union[transformers.PreTrainedModel, peft.peft_model.PeftModelForCausalLM],\n",
    ") -> None:\n",
    "\n",
    "    dev_df = get_df_in_hendrycks_format(subject=subject, split=\"dev\", lang=lang)\n",
    "    test_df = get_df_in_hendrycks_format(subject=subject, split=\"test\", lang=lang)\n",
    "\n",
    "    for idx, row in tqdm(test_df.iterrows(), total=len(test_df), desc=subject):\n",
    "\n",
    "        current_k_shot = k_shot\n",
    "        skip_too_lengthy = False\n",
    "        while True:\n",
    "            if current_k_shot < 0:\n",
    "                logger.info(\"Skip too lengthy.\")\n",
    "                skip_too_lengthy = True\n",
    "                break\n",
    "            input_messages = get_prompt_from_dataframes(\n",
    "                dev_df=dev_df,\n",
    "                test_df=test_df,\n",
    "                k=current_k_shot,\n",
    "                test_iloc_idx=idx,\n",
    "                lang=lang,\n",
    "                subject=subject,\n",
    "                conversation_type=convtype,\n",
    "            )\n",
    "            input_prompt = tokenizer.apply_chat_template(input_messages, tokenize=False, add_special_tokens=False, add_generation_prompt=True)\n",
    "            input_ids = tokenizer.encode(input_prompt, return_tensors=\"pt\", add_special_tokens=False).to(model.device)\n",
    "\n",
    "            if input_ids.shape[-1] > maxlen and current_k_shot >= 0:\n",
    "                logger.info(\"Takes smaller current_k_shot since maxlen.\")\n",
    "                current_k_shot -= 1\n",
    "            elif current_k_shot < 0:\n",
    "                logger.info(\"Skip too lengthy.\")\n",
    "                skip_too_lengthy = True\n",
    "            else:\n",
    "                break\n",
    "        if skip_too_lengthy:\n",
    "            continue\n",
    "\n",
    "        label = row[5]\n",
    "\n",
    "        preds = calculate_token_interest_probs(\n",
    "            input_ids=input_ids,\n",
    "            tokenizer=tokenizer,\n",
    "            model=model,\n",
    "        )\n",
    "\n",
    "        append_to_jsonl(data=[input_prompt, label, preds], filename=jsonl_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3935963-d5d7-4b60-b69c-08436870a4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# lang = \"en\"\n",
    "# subject = \"high_school_european_history\"\n",
    "# convtype = \"empy_prompt_conv\"\n",
    "# current_k_shot = 5\n",
    "# idx = 5\n",
    "# dev_df = get_df_in_hendrycks_format(subject=subject, split=\"dev\", lang=lang)\n",
    "# test_df = get_df_in_hendrycks_format(subject=subject, split=\"test\", lang=lang)\n",
    "\n",
    "# input_messages = get_prompt_from_dataframes(\n",
    "#     dev_df=dev_df,\n",
    "#     test_df=test_df,\n",
    "#     k=current_k_shot,\n",
    "#     test_iloc_idx=idx,\n",
    "#     lang=lang,\n",
    "#     subject=subject,\n",
    "#     conversation_type=convtype,\n",
    "# )\n",
    "# input_prompt = tokenizer.apply_chat_template(input_messages, tokenize=False, add_special_tokens=False, add_generation_prompt=True)\n",
    "# print(input_prompt)\n",
    "# input_ids = tokenizer.encode(input_prompt, return_tensors=\"pt\", add_special_tokens=False).to(model.device)\n",
    "# with torch.inference_mode():\n",
    "#     output_ids = model.generate(input_ids, pad_token_id=tokenizer.eos_token_id, max_new_tokens=10)\n",
    "# ouput_str = tokenizer.decode(output_ids[0])\n",
    "# ouput_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8e07f7-1edf-4ecf-a86c-ecee3959fe01",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"mmlu_en_Phi-3-medium-128k-instruct\"\n",
    "lang = \"en\"\n",
    "k_shot = 5\n",
    "convtype = \"empy_prompt_conv\"\n",
    "MAX_INPUT_LENGTH = 8192\n",
    "\n",
    "subjects = list(subcategories.keys())\n",
    "for each_subject in subjects:\n",
    "    jsonl_filepath = str(pathlib.Path(output_dir) / f\"{each_subject}.jsonl\")\n",
    "    pathlib.Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "    logger.info(f\"Filepath JSONL: {jsonl_filepath}\")\n",
    "    if pathlib.Path(jsonl_filepath).exists():\n",
    "        logger.info(f\"File already exists! Please manually verify that it wasn't partially interrupted.\")\n",
    "        continue\n",
    "    evaluate_subject(\n",
    "            subject=each_subject,\n",
    "            lang=lang,\n",
    "            k_shot=k_shot,\n",
    "            jsonl_filepath=jsonl_filepath,\n",
    "            maxlen=MAX_INPUT_LENGTH, convtype=convtype,\n",
    "            tokenizer=tokenizer,\n",
    "            model=model,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4562c7-f428-4804-af3f-024eedb1da9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"mmlu_ru_Phi-3-medium-128k-instruct\"\n",
    "lang = \"ru\"\n",
    "k_shot = 5\n",
    "convtype = \"empy_prompt_conv\"\n",
    "MAX_INPUT_LENGTH = 8192\n",
    "\n",
    "subjects = list(subcategories.keys())\n",
    "for each_subject in subjects:\n",
    "    jsonl_filepath = str(pathlib.Path(output_dir) / f\"{each_subject}.jsonl\")\n",
    "    pathlib.Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "    logger.info(f\"Filepath JSONL: {jsonl_filepath}\")\n",
    "    if pathlib.Path(jsonl_filepath).exists():\n",
    "        logger.info(f\"File already exists! Please manually verify that it wasn't partially interrupted.\")\n",
    "        continue\n",
    "    evaluate_subject(\n",
    "            subject=each_subject,\n",
    "            lang=lang,\n",
    "            k_shot=k_shot,\n",
    "            jsonl_filepath=jsonl_filepath,\n",
    "            maxlen=MAX_INPUT_LENGTH, convtype=convtype,\n",
    "            tokenizer=tokenizer,\n",
    "            model=model,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2990dd5-47ce-408f-a0f6-e8929587e95b",
   "metadata": {},
   "source": [
    "## MMLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4f1ad55-2826-45dd-a5e1-874421a37218",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "category_to_main_category = {value: key for key, sublist in categories.items() for value in sublist}\n",
    "subcategories2categories = {key: category_to_main_category[value[0]] for key, value in subcategories.items()}\n",
    "\n",
    "def calculate_accuracy_from_directory(dirpath: str) -> tp.Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    assert pathlib.Path(dirpath).exists()\n",
    "    filepaths = [str(x) for x in pathlib.Path(dirpath).glob('*.jsonl')]\n",
    "    # assert len(filepaths) == 57\n",
    "    res = {}\n",
    "    for each_filepath in filepaths:\n",
    "        df = pd.read_json(each_filepath, lines=True)\n",
    "        df.columns = ['prompt', 'label', 'preds']\n",
    "        cors = []\n",
    "        for idx, row in df.iterrows():\n",
    "            preds = row['preds']\n",
    "            best_idx = np.argmax(list(preds.values()))\n",
    "            y_pred = list(preds.keys())[best_idx]\n",
    "            y_true = row['label']\n",
    "            y_pred = y_pred.strip()\n",
    "            y_true = y_true.strip()\n",
    "            cors.append(y_true == y_pred)\n",
    "        acc = np.mean(cors)\n",
    "        res[pathlib.Path(each_filepath).stem] = acc * 100\n",
    "    \n",
    "    df = pd.DataFrame({pathlib.Path(dirpath).stem: res}).reset_index()\n",
    "    df = df.rename(columns={'index': 'subcategory'})\n",
    "    subcategories_df = df.copy()\n",
    "    \n",
    "    df = subcategories_df.copy()\n",
    "    df['subcategory'] = df['subcategory'].map(subcategories2categories)\n",
    "    df = df.rename(columns={'subcategory': 'category'})\n",
    "    df = df.groupby('category').mean().reset_index()\n",
    "    categories_df = df.copy()\n",
    "    \n",
    "    total_df = pd.DataFrame({pathlib.Path(dirpath).stem: [categories_df[pathlib.Path(dirpath).stem].mean()]})\n",
    "    \n",
    "    # assert subcategories_df.shape == (57, 2)\n",
    "    # assert categories_df.shape == (4, 2)\n",
    "    # assert total_df.shape == (1, 1)\n",
    "    return (subcategories_df, categories_df, total_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fba5a286-ddda-4d49-a0f2-b9d7397abf4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mmlu 72.25579699595872\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subcategory</th>\n",
       "      <th>mmlu_en_Phi-3-medium-128k-instruct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abstract_algebra</td>\n",
       "      <td>55.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anatomy</td>\n",
       "      <td>72.592593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>astronomy</td>\n",
       "      <td>86.184211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business_ethics</td>\n",
       "      <td>80.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>clinical_knowledge</td>\n",
       "      <td>82.641509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>college_biology</td>\n",
       "      <td>89.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>college_chemistry</td>\n",
       "      <td>54.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>college_computer_science</td>\n",
       "      <td>66.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>college_mathematics</td>\n",
       "      <td>49.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>college_medicine</td>\n",
       "      <td>76.300578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                subcategory  mmlu_en_Phi-3-medium-128k-instruct\n",
       "0          abstract_algebra                           55.000000\n",
       "1                   anatomy                           72.592593\n",
       "2                 astronomy                           86.184211\n",
       "3           business_ethics                           80.000000\n",
       "4        clinical_knowledge                           82.641509\n",
       "5           college_biology                           89.583333\n",
       "6         college_chemistry                           54.000000\n",
       "7  college_computer_science                           66.000000\n",
       "8       college_mathematics                           49.000000\n",
       "9          college_medicine                           76.300578"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir = \"mmlu_en_Phi-3-medium-128k-instruct\"\n",
    "\n",
    "subcategories_df, categories_df, total_df = calculate_accuracy_from_directory(dirpath=output_dir)\n",
    "print(\"mmlu\", total_df.values[0][0])\n",
    "subcategories_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "68dca338-9169-433b-b265-31a7e50e8bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mmlu 68.66153356444299\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subcategory</th>\n",
       "      <th>mmlu_ru_Phi-3-medium-128k-instruct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abstract_algebra</td>\n",
       "      <td>51.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anatomy</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>astronomy</td>\n",
       "      <td>80.921053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business_ethics</td>\n",
       "      <td>71.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>clinical_knowledge</td>\n",
       "      <td>71.320755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>college_biology</td>\n",
       "      <td>81.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>college_chemistry</td>\n",
       "      <td>57.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>college_computer_science</td>\n",
       "      <td>59.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>college_mathematics</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>college_medicine</td>\n",
       "      <td>68.208092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>college_physics</td>\n",
       "      <td>45.098039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>computer_security</td>\n",
       "      <td>70.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>conceptual_physics</td>\n",
       "      <td>72.765957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>econometrics</td>\n",
       "      <td>51.754386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>electrical_engineering</td>\n",
       "      <td>57.241379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>elementary_mathematics</td>\n",
       "      <td>52.910053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>formal_logic</td>\n",
       "      <td>57.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>global_facts</td>\n",
       "      <td>44.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>high_school_biology</td>\n",
       "      <td>82.258065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>high_school_chemistry</td>\n",
       "      <td>61.576355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>high_school_computer_science</td>\n",
       "      <td>76.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>high_school_european_history</td>\n",
       "      <td>78.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>high_school_geography</td>\n",
       "      <td>80.808081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>high_school_government_and_politics</td>\n",
       "      <td>85.492228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>high_school_macroeconomics</td>\n",
       "      <td>76.410256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>high_school_mathematics</td>\n",
       "      <td>40.370370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>high_school_microeconomics</td>\n",
       "      <td>81.512605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>high_school_physics</td>\n",
       "      <td>56.291391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>high_school_psychology</td>\n",
       "      <td>84.036697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>high_school_statistics</td>\n",
       "      <td>62.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>high_school_us_history</td>\n",
       "      <td>79.901961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>high_school_world_history</td>\n",
       "      <td>82.700422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>human_aging</td>\n",
       "      <td>67.713004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>human_sexuality</td>\n",
       "      <td>74.045802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>international_law</td>\n",
       "      <td>81.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>jurisprudence</td>\n",
       "      <td>70.370370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>logical_fallacies</td>\n",
       "      <td>72.392638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>machine_learning</td>\n",
       "      <td>60.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>management</td>\n",
       "      <td>77.669903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>marketing</td>\n",
       "      <td>82.051282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>medical_genetics</td>\n",
       "      <td>62.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>miscellaneous</td>\n",
       "      <td>69.859515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>moral_disputes</td>\n",
       "      <td>71.098266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>moral_scenarios</td>\n",
       "      <td>56.759777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>nutrition</td>\n",
       "      <td>73.856209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>philosophy</td>\n",
       "      <td>69.453376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>prehistory</td>\n",
       "      <td>69.135802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>professional_accounting</td>\n",
       "      <td>52.127660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>professional_law</td>\n",
       "      <td>50.195567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            subcategory  mmlu_ru_Phi-3-medium-128k-instruct\n",
       "0                      abstract_algebra                           51.000000\n",
       "1                               anatomy                           60.000000\n",
       "2                             astronomy                           80.921053\n",
       "3                       business_ethics                           71.000000\n",
       "4                    clinical_knowledge                           71.320755\n",
       "5                       college_biology                           81.250000\n",
       "6                     college_chemistry                           57.000000\n",
       "7              college_computer_science                           59.000000\n",
       "8                   college_mathematics                           45.000000\n",
       "9                      college_medicine                           68.208092\n",
       "10                      college_physics                           45.098039\n",
       "11                    computer_security                           70.000000\n",
       "12                   conceptual_physics                           72.765957\n",
       "13                         econometrics                           51.754386\n",
       "14               electrical_engineering                           57.241379\n",
       "15               elementary_mathematics                           52.910053\n",
       "16                         formal_logic                           57.142857\n",
       "17                         global_facts                           44.000000\n",
       "18                  high_school_biology                           82.258065\n",
       "19                high_school_chemistry                           61.576355\n",
       "20         high_school_computer_science                           76.000000\n",
       "21         high_school_european_history                           78.181818\n",
       "22                high_school_geography                           80.808081\n",
       "23  high_school_government_and_politics                           85.492228\n",
       "24           high_school_macroeconomics                           76.410256\n",
       "25              high_school_mathematics                           40.370370\n",
       "26           high_school_microeconomics                           81.512605\n",
       "27                  high_school_physics                           56.291391\n",
       "28               high_school_psychology                           84.036697\n",
       "29               high_school_statistics                           62.500000\n",
       "30               high_school_us_history                           79.901961\n",
       "31            high_school_world_history                           82.700422\n",
       "32                          human_aging                           67.713004\n",
       "33                      human_sexuality                           74.045802\n",
       "34                    international_law                           81.818182\n",
       "35                        jurisprudence                           70.370370\n",
       "36                    logical_fallacies                           72.392638\n",
       "37                     machine_learning                           60.714286\n",
       "38                           management                           77.669903\n",
       "39                            marketing                           82.051282\n",
       "40                     medical_genetics                           62.000000\n",
       "41                        miscellaneous                           69.859515\n",
       "42                       moral_disputes                           71.098266\n",
       "43                      moral_scenarios                           56.759777\n",
       "44                            nutrition                           73.856209\n",
       "45                           philosophy                           69.453376\n",
       "46                           prehistory                           69.135802\n",
       "47              professional_accounting                           52.127660\n",
       "48                     professional_law                           50.195567"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir = \"mmlu_ru_Phi-3-medium-128k-instruct\"\n",
    "\n",
    "subcategories_df, categories_df, total_df = calculate_accuracy_from_directory(dirpath=output_dir)\n",
    "print(\"mmlu\", total_df.values[0][0])\n",
    "subcategories_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabfbd61-6c9d-4278-9980-35d334afeb65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
